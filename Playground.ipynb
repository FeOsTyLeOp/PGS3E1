{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import optuna\n",
    "\n",
    "bold = ['\\033[1m', '\\033[0m']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will be predicting  the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000). The independent variables at our disposal are:\n",
    "\n",
    "MedInc - median income in block group\n",
    "HouseAge - median house age in block group\n",
    "AveRooms - average number of rooms per household\n",
    "AveBedrms - average number of bedrooms per household\n",
    "Population - block group population\n",
    "AveOccup - average number of household members\n",
    "Latitude - block group latitude\n",
    "Longitude - block group longitude\n",
    "The evaluation metric is going the be the standard Root Mean Squared Error (RMSE) and the useful thing to keep in mind about this metric, as it involves a squared term, is that outliers, or predictions that err a lot, are disproportionately penalized!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing as fch\n",
    "\n",
    "sklearn_df = pd.DataFrame(fch()['data'], columns=fch()['feature_names'])\n",
    "sklearn_df['MedHouseVal'] = fch()['target']\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "sklearn_df['is_generated'] = 0\n",
    "train['is_generated'] = 1\n",
    "test['is_generated'] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "train.drop('id', axis=1, inplace=True)\n",
    "train = pd.concat([train, sklearn_df],\n",
    "                  ignore_index=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0      2.3859      15.0  3.827160   1.112100      1280.0  2.486989     34.60   \n1      3.7188      17.0  6.013373   1.054217      1504.0  3.813084     38.69   \n2      4.7750      27.0  6.535604   1.103175      1061.0  2.464602     34.71   \n3      2.4138      16.0  3.350203   0.965432      1255.0  2.089286     32.66   \n4      3.7500      52.0  4.284404   1.069246      1793.0  1.604790     37.80   \n...       ...       ...       ...        ...         ...       ...       ...   \n57772  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n57773  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n57774  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n57775  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n57776  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n\n       Longitude  MedHouseVal  is_generated  \n0        -120.12        0.980             1  \n1        -121.22        0.946             1  \n2        -120.45        1.576             1  \n3        -117.09        1.336             1  \n4        -122.41        4.500             1  \n...          ...          ...           ...  \n57772    -121.09        0.781             0  \n57773    -121.21        0.771             0  \n57774    -121.22        0.923             0  \n57775    -121.32        0.847             0  \n57776    -121.24        0.894             0  \n\n[57777 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedHouseVal</th>\n      <th>is_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.3859</td>\n      <td>15.0</td>\n      <td>3.827160</td>\n      <td>1.112100</td>\n      <td>1280.0</td>\n      <td>2.486989</td>\n      <td>34.60</td>\n      <td>-120.12</td>\n      <td>0.980</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.7188</td>\n      <td>17.0</td>\n      <td>6.013373</td>\n      <td>1.054217</td>\n      <td>1504.0</td>\n      <td>3.813084</td>\n      <td>38.69</td>\n      <td>-121.22</td>\n      <td>0.946</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7750</td>\n      <td>27.0</td>\n      <td>6.535604</td>\n      <td>1.103175</td>\n      <td>1061.0</td>\n      <td>2.464602</td>\n      <td>34.71</td>\n      <td>-120.45</td>\n      <td>1.576</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.4138</td>\n      <td>16.0</td>\n      <td>3.350203</td>\n      <td>0.965432</td>\n      <td>1255.0</td>\n      <td>2.089286</td>\n      <td>32.66</td>\n      <td>-117.09</td>\n      <td>1.336</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.7500</td>\n      <td>52.0</td>\n      <td>4.284404</td>\n      <td>1.069246</td>\n      <td>1793.0</td>\n      <td>1.604790</td>\n      <td>37.80</td>\n      <td>-122.41</td>\n      <td>4.500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57772</th>\n      <td>1.5603</td>\n      <td>25.0</td>\n      <td>5.045455</td>\n      <td>1.133333</td>\n      <td>845.0</td>\n      <td>2.560606</td>\n      <td>39.48</td>\n      <td>-121.09</td>\n      <td>0.781</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57773</th>\n      <td>2.5568</td>\n      <td>18.0</td>\n      <td>6.114035</td>\n      <td>1.315789</td>\n      <td>356.0</td>\n      <td>3.122807</td>\n      <td>39.49</td>\n      <td>-121.21</td>\n      <td>0.771</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57774</th>\n      <td>1.7000</td>\n      <td>17.0</td>\n      <td>5.205543</td>\n      <td>1.120092</td>\n      <td>1007.0</td>\n      <td>2.325635</td>\n      <td>39.43</td>\n      <td>-121.22</td>\n      <td>0.923</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57775</th>\n      <td>1.8672</td>\n      <td>18.0</td>\n      <td>5.329513</td>\n      <td>1.171920</td>\n      <td>741.0</td>\n      <td>2.123209</td>\n      <td>39.43</td>\n      <td>-121.32</td>\n      <td>0.847</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57776</th>\n      <td>2.3886</td>\n      <td>16.0</td>\n      <td>5.254717</td>\n      <td>1.162264</td>\n      <td>1387.0</td>\n      <td>2.616981</td>\n      <td>39.37</td>\n      <td>-121.24</td>\n      <td>0.894</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57777 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def crt_crds(df):\n",
    "    df['rot_15_x'] = (np.cos(np.radians(15)) * df['Longitude']) + (np.sin(np.radians(15)) * df['Latitude'])\n",
    "\n",
    "    df['rot_15_y'] = (np.cos(np.radians(15)) * df['Latitude']) + (np.sin(np.radians(15)) * df['Longitude'])\n",
    "\n",
    "    df['rot_30_x'] = (np.cos(np.radians(30)) * df['Longitude']) + (np.sin(np.radians(30)) * df['Latitude'])\n",
    "\n",
    "    df['rot_30_y'] = (np.cos(np.radians(30)) * df['Latitude']) + (np.sin(np.radians(30)) * df['Longitude'])\n",
    "\n",
    "    df['rot_45_x'] = (np.cos(np.radians(45)) * df['Longitude']) + (np.sin(np.radians(45)) * df['Latitude'])\n",
    "    return df\n",
    "\n",
    "\n",
    "train = crt_crds(train)\n",
    "test = crt_crds(test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0      2.3859      15.0  3.827160   1.112100      1280.0  2.486989     34.60   \n1      3.7188      17.0  6.013373   1.054217      1504.0  3.813084     38.69   \n2      4.7750      27.0  6.535604   1.103175      1061.0  2.464602     34.71   \n3      2.4138      16.0  3.350203   0.965432      1255.0  2.089286     32.66   \n4      3.7500      52.0  4.284404   1.069246      1793.0  1.604790     37.80   \n...       ...       ...       ...        ...         ...       ...       ...   \n57772  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n57773  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n57774  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n57775  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n57776  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n\n       Longitude  MedHouseVal  is_generated    rot_15_x  rot_15_y   rot_30_x  \\\n0        -120.12        0.980             1 -107.071871  2.331690 -86.726972   \n1        -121.22        0.946             1 -107.075820  5.997626 -85.634599   \n2        -120.45        1.576             1 -107.362157  2.352531 -86.957760   \n3        -117.09        1.336             1 -104.647225  1.242015 -85.072915   \n4        -122.41        4.500             1 -108.455620  4.829957 -87.110170   \n...          ...          ...           ...         ...       ...        ...   \n57772    -121.09        0.781             0 -106.745782  6.794353 -85.127016   \n57773    -121.21        0.771             0 -106.859105  6.772954 -85.225939   \n57774    -121.22        0.923             0 -106.884294  6.712411 -85.264599   \n57775    -121.32        0.847             0 -106.980886  6.686529 -85.351202   \n57776    -121.24        0.894             0 -106.919141  6.649279 -85.311920   \n\n        rot_30_y   rot_45_x  \n0     -30.095521 -60.471772  \n1     -27.103477 -58.357523  \n2     -30.165258 -60.627335  \n3     -30.260610 -59.701026  \n4     -28.469240 -59.828305  \n...          ...        ...  \n57772 -26.354317 -57.706984  \n57773 -26.405657 -57.784766  \n57774 -26.462618 -57.834264  \n57775 -26.512618 -57.904974  \n57776 -26.524580 -57.890832  \n\n[57777 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedHouseVal</th>\n      <th>is_generated</th>\n      <th>rot_15_x</th>\n      <th>rot_15_y</th>\n      <th>rot_30_x</th>\n      <th>rot_30_y</th>\n      <th>rot_45_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.3859</td>\n      <td>15.0</td>\n      <td>3.827160</td>\n      <td>1.112100</td>\n      <td>1280.0</td>\n      <td>2.486989</td>\n      <td>34.60</td>\n      <td>-120.12</td>\n      <td>0.980</td>\n      <td>1</td>\n      <td>-107.071871</td>\n      <td>2.331690</td>\n      <td>-86.726972</td>\n      <td>-30.095521</td>\n      <td>-60.471772</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.7188</td>\n      <td>17.0</td>\n      <td>6.013373</td>\n      <td>1.054217</td>\n      <td>1504.0</td>\n      <td>3.813084</td>\n      <td>38.69</td>\n      <td>-121.22</td>\n      <td>0.946</td>\n      <td>1</td>\n      <td>-107.075820</td>\n      <td>5.997626</td>\n      <td>-85.634599</td>\n      <td>-27.103477</td>\n      <td>-58.357523</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7750</td>\n      <td>27.0</td>\n      <td>6.535604</td>\n      <td>1.103175</td>\n      <td>1061.0</td>\n      <td>2.464602</td>\n      <td>34.71</td>\n      <td>-120.45</td>\n      <td>1.576</td>\n      <td>1</td>\n      <td>-107.362157</td>\n      <td>2.352531</td>\n      <td>-86.957760</td>\n      <td>-30.165258</td>\n      <td>-60.627335</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.4138</td>\n      <td>16.0</td>\n      <td>3.350203</td>\n      <td>0.965432</td>\n      <td>1255.0</td>\n      <td>2.089286</td>\n      <td>32.66</td>\n      <td>-117.09</td>\n      <td>1.336</td>\n      <td>1</td>\n      <td>-104.647225</td>\n      <td>1.242015</td>\n      <td>-85.072915</td>\n      <td>-30.260610</td>\n      <td>-59.701026</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.7500</td>\n      <td>52.0</td>\n      <td>4.284404</td>\n      <td>1.069246</td>\n      <td>1793.0</td>\n      <td>1.604790</td>\n      <td>37.80</td>\n      <td>-122.41</td>\n      <td>4.500</td>\n      <td>1</td>\n      <td>-108.455620</td>\n      <td>4.829957</td>\n      <td>-87.110170</td>\n      <td>-28.469240</td>\n      <td>-59.828305</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57772</th>\n      <td>1.5603</td>\n      <td>25.0</td>\n      <td>5.045455</td>\n      <td>1.133333</td>\n      <td>845.0</td>\n      <td>2.560606</td>\n      <td>39.48</td>\n      <td>-121.09</td>\n      <td>0.781</td>\n      <td>0</td>\n      <td>-106.745782</td>\n      <td>6.794353</td>\n      <td>-85.127016</td>\n      <td>-26.354317</td>\n      <td>-57.706984</td>\n    </tr>\n    <tr>\n      <th>57773</th>\n      <td>2.5568</td>\n      <td>18.0</td>\n      <td>6.114035</td>\n      <td>1.315789</td>\n      <td>356.0</td>\n      <td>3.122807</td>\n      <td>39.49</td>\n      <td>-121.21</td>\n      <td>0.771</td>\n      <td>0</td>\n      <td>-106.859105</td>\n      <td>6.772954</td>\n      <td>-85.225939</td>\n      <td>-26.405657</td>\n      <td>-57.784766</td>\n    </tr>\n    <tr>\n      <th>57774</th>\n      <td>1.7000</td>\n      <td>17.0</td>\n      <td>5.205543</td>\n      <td>1.120092</td>\n      <td>1007.0</td>\n      <td>2.325635</td>\n      <td>39.43</td>\n      <td>-121.22</td>\n      <td>0.923</td>\n      <td>0</td>\n      <td>-106.884294</td>\n      <td>6.712411</td>\n      <td>-85.264599</td>\n      <td>-26.462618</td>\n      <td>-57.834264</td>\n    </tr>\n    <tr>\n      <th>57775</th>\n      <td>1.8672</td>\n      <td>18.0</td>\n      <td>5.329513</td>\n      <td>1.171920</td>\n      <td>741.0</td>\n      <td>2.123209</td>\n      <td>39.43</td>\n      <td>-121.32</td>\n      <td>0.847</td>\n      <td>0</td>\n      <td>-106.980886</td>\n      <td>6.686529</td>\n      <td>-85.351202</td>\n      <td>-26.512618</td>\n      <td>-57.904974</td>\n    </tr>\n    <tr>\n      <th>57776</th>\n      <td>2.3886</td>\n      <td>16.0</td>\n      <td>5.254717</td>\n      <td>1.162264</td>\n      <td>1387.0</td>\n      <td>2.616981</td>\n      <td>39.37</td>\n      <td>-121.24</td>\n      <td>0.894</td>\n      <td>0</td>\n      <td>-106.919141</td>\n      <td>6.649279</td>\n      <td>-85.311920</td>\n      <td>-26.524580</td>\n      <td>-57.890832</td>\n    </tr>\n  </tbody>\n</table>\n<p>57777 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import reverse_geocoder as rg\n",
    "\n",
    "\n",
    "def geocoder(df):\n",
    "    coordinates = list(zip(df['Latitude'], df['Longitude']))\n",
    "    results = rg.search(coordinates)\n",
    "    return results\n",
    "\n",
    "\n",
    "results = geocoder(train)\n",
    "train['place'] = [x['admin2'] for x in results]\n",
    "results = geocoder(test)\n",
    "test['place'] = [x['admin2'] for x in results]\n",
    "\n",
    "places = ['Los Angeles County', 'Orange County', 'Kern County',\n",
    "          'Alameda County', 'San Francisco County', 'Ventura County',\n",
    "          'Santa Clara County', 'Fresno County', 'Santa Barbara County',\n",
    "          'Contra Costa County', 'Yolo County', 'Monterey County',\n",
    "          'Riverside County', 'Napa County']\n",
    "\n",
    "\n",
    "def replace(x):\n",
    "    if x in places:\n",
    "        return x\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "\n",
    "train['place'] = train['place'].apply(lambda x: replace(x))\n",
    "test['place'] = test['place'].apply(lambda x: replace(x))\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['place'] = le.fit_transform(train['place'])\n",
    "test['place'] = le.transform(test['place'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0      2.3859      15.0  3.827160   1.112100      1280.0  2.486989     34.60   \n1      3.7188      17.0  6.013373   1.054217      1504.0  3.813084     38.69   \n2      4.7750      27.0  6.535604   1.103175      1061.0  2.464602     34.71   \n3      2.4138      16.0  3.350203   0.965432      1255.0  2.089286     32.66   \n4      3.7500      52.0  4.284404   1.069246      1793.0  1.604790     37.80   \n...       ...       ...       ...        ...         ...       ...       ...   \n57772  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n57773  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n57774  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n57775  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n57776  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n\n       Longitude  MedHouseVal  is_generated    rot_15_x  rot_15_y   rot_30_x  \\\n0        -120.12        0.980             1 -107.071871  2.331690 -86.726972   \n1        -121.22        0.946             1 -107.075820  5.997626 -85.634599   \n2        -120.45        1.576             1 -107.362157  2.352531 -86.957760   \n3        -117.09        1.336             1 -104.647225  1.242015 -85.072915   \n4        -122.41        4.500             1 -108.455620  4.829957 -87.110170   \n...          ...          ...           ...         ...       ...        ...   \n57772    -121.09        0.781             0 -106.745782  6.794353 -85.127016   \n57773    -121.21        0.771             0 -106.859105  6.772954 -85.225939   \n57774    -121.22        0.923             0 -106.884294  6.712411 -85.264599   \n57775    -121.32        0.847             0 -106.980886  6.686529 -85.351202   \n57776    -121.24        0.894             0 -106.919141  6.649279 -85.311920   \n\n        rot_30_y   rot_45_x  place  \n0     -30.095521 -60.471772     11  \n1     -27.103477 -58.357523      8  \n2     -30.165258 -60.627335     11  \n3     -30.260610 -59.701026      8  \n4     -28.469240 -59.828305     10  \n...          ...        ...    ...  \n57772 -26.354317 -57.706984      8  \n57773 -26.405657 -57.784766      8  \n57774 -26.462618 -57.834264      8  \n57775 -26.512618 -57.904974      8  \n57776 -26.524580 -57.890832      8  \n\n[57777 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedHouseVal</th>\n      <th>is_generated</th>\n      <th>rot_15_x</th>\n      <th>rot_15_y</th>\n      <th>rot_30_x</th>\n      <th>rot_30_y</th>\n      <th>rot_45_x</th>\n      <th>place</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.3859</td>\n      <td>15.0</td>\n      <td>3.827160</td>\n      <td>1.112100</td>\n      <td>1280.0</td>\n      <td>2.486989</td>\n      <td>34.60</td>\n      <td>-120.12</td>\n      <td>0.980</td>\n      <td>1</td>\n      <td>-107.071871</td>\n      <td>2.331690</td>\n      <td>-86.726972</td>\n      <td>-30.095521</td>\n      <td>-60.471772</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.7188</td>\n      <td>17.0</td>\n      <td>6.013373</td>\n      <td>1.054217</td>\n      <td>1504.0</td>\n      <td>3.813084</td>\n      <td>38.69</td>\n      <td>-121.22</td>\n      <td>0.946</td>\n      <td>1</td>\n      <td>-107.075820</td>\n      <td>5.997626</td>\n      <td>-85.634599</td>\n      <td>-27.103477</td>\n      <td>-58.357523</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7750</td>\n      <td>27.0</td>\n      <td>6.535604</td>\n      <td>1.103175</td>\n      <td>1061.0</td>\n      <td>2.464602</td>\n      <td>34.71</td>\n      <td>-120.45</td>\n      <td>1.576</td>\n      <td>1</td>\n      <td>-107.362157</td>\n      <td>2.352531</td>\n      <td>-86.957760</td>\n      <td>-30.165258</td>\n      <td>-60.627335</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.4138</td>\n      <td>16.0</td>\n      <td>3.350203</td>\n      <td>0.965432</td>\n      <td>1255.0</td>\n      <td>2.089286</td>\n      <td>32.66</td>\n      <td>-117.09</td>\n      <td>1.336</td>\n      <td>1</td>\n      <td>-104.647225</td>\n      <td>1.242015</td>\n      <td>-85.072915</td>\n      <td>-30.260610</td>\n      <td>-59.701026</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.7500</td>\n      <td>52.0</td>\n      <td>4.284404</td>\n      <td>1.069246</td>\n      <td>1793.0</td>\n      <td>1.604790</td>\n      <td>37.80</td>\n      <td>-122.41</td>\n      <td>4.500</td>\n      <td>1</td>\n      <td>-108.455620</td>\n      <td>4.829957</td>\n      <td>-87.110170</td>\n      <td>-28.469240</td>\n      <td>-59.828305</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57772</th>\n      <td>1.5603</td>\n      <td>25.0</td>\n      <td>5.045455</td>\n      <td>1.133333</td>\n      <td>845.0</td>\n      <td>2.560606</td>\n      <td>39.48</td>\n      <td>-121.09</td>\n      <td>0.781</td>\n      <td>0</td>\n      <td>-106.745782</td>\n      <td>6.794353</td>\n      <td>-85.127016</td>\n      <td>-26.354317</td>\n      <td>-57.706984</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>57773</th>\n      <td>2.5568</td>\n      <td>18.0</td>\n      <td>6.114035</td>\n      <td>1.315789</td>\n      <td>356.0</td>\n      <td>3.122807</td>\n      <td>39.49</td>\n      <td>-121.21</td>\n      <td>0.771</td>\n      <td>0</td>\n      <td>-106.859105</td>\n      <td>6.772954</td>\n      <td>-85.225939</td>\n      <td>-26.405657</td>\n      <td>-57.784766</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>57774</th>\n      <td>1.7000</td>\n      <td>17.0</td>\n      <td>5.205543</td>\n      <td>1.120092</td>\n      <td>1007.0</td>\n      <td>2.325635</td>\n      <td>39.43</td>\n      <td>-121.22</td>\n      <td>0.923</td>\n      <td>0</td>\n      <td>-106.884294</td>\n      <td>6.712411</td>\n      <td>-85.264599</td>\n      <td>-26.462618</td>\n      <td>-57.834264</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>57775</th>\n      <td>1.8672</td>\n      <td>18.0</td>\n      <td>5.329513</td>\n      <td>1.171920</td>\n      <td>741.0</td>\n      <td>2.123209</td>\n      <td>39.43</td>\n      <td>-121.32</td>\n      <td>0.847</td>\n      <td>0</td>\n      <td>-106.980886</td>\n      <td>6.686529</td>\n      <td>-85.351202</td>\n      <td>-26.512618</td>\n      <td>-57.904974</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>57776</th>\n      <td>2.3886</td>\n      <td>16.0</td>\n      <td>5.254717</td>\n      <td>1.162264</td>\n      <td>1387.0</td>\n      <td>2.616981</td>\n      <td>39.37</td>\n      <td>-121.24</td>\n      <td>0.894</td>\n      <td>0</td>\n      <td>-106.919141</td>\n      <td>6.649279</td>\n      <td>-85.311920</td>\n      <td>-26.524580</td>\n      <td>-57.890832</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>57777 rows Ã— 16 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def pca_crds(df):\n",
    "    coordinates = df[['Latitude', 'Longitude']].values\n",
    "    pca_obj = PCA().fit(coordinates)\n",
    "    df['pca_lat'] = pca_obj.transform(df[['Latitude', 'Longitude']])[:, 0]\n",
    "    df['pca_lon'] = pca_obj.transform(df[['Latitude', 'Longitude']])[:, 1]\n",
    "    return df\n",
    "\n",
    "\n",
    "train = pca_crds(train)\n",
    "test = pca_crds(test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0      2.3859      15.0  3.827160   1.112100      1280.0  2.486989     34.60   \n1      3.7188      17.0  6.013373   1.054217      1504.0  3.813084     38.69   \n2      4.7750      27.0  6.535604   1.103175      1061.0  2.464602     34.71   \n3      2.4138      16.0  3.350203   0.965432      1255.0  2.089286     32.66   \n4      3.7500      52.0  4.284404   1.069246      1793.0  1.604790     37.80   \n...       ...       ...       ...        ...         ...       ...       ...   \n57772  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n57773  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n57774  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n57775  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n57776  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n\n       Longitude  MedHouseVal  is_generated    rot_15_x  rot_15_y   rot_30_x  \\\n0        -120.12        0.980             1 -107.071871  2.331690 -86.726972   \n1        -121.22        0.946             1 -107.075820  5.997626 -85.634599   \n2        -120.45        1.576             1 -107.362157  2.352531 -86.957760   \n3        -117.09        1.336             1 -104.647225  1.242015 -85.072915   \n4        -122.41        4.500             1 -108.455620  4.829957 -87.110170   \n...          ...          ...           ...         ...       ...        ...   \n57772    -121.09        0.781             0 -106.745782  6.794353 -85.127016   \n57773    -121.21        0.771             0 -106.859105  6.772954 -85.225939   \n57774    -121.22        0.923             0 -106.884294  6.712411 -85.264599   \n57775    -121.32        0.847             0 -106.980886  6.686529 -85.351202   \n57776    -121.24        0.894             0 -106.919141  6.649279 -85.311920   \n\n        rot_30_y   rot_45_x  place   pca_lat   pca_lon  \n0     -30.095521 -60.471772     11 -0.339172 -1.087686  \n1     -27.103477 -58.357523      8  3.394240  0.912247  \n2     -30.165258 -60.627335     11 -0.032996 -1.252781  \n3     -30.260610 -59.701026      8 -3.828020 -0.208802  \n4     -28.469240 -59.828305     10  3.560861 -0.564383  \n...          ...        ...    ...       ...       ...  \n57772 -26.354317 -57.706984      8  3.880794  1.548066  \n57773 -26.405657 -57.784766      8  3.970272  1.467483  \n57774 -26.462618 -57.834264      8  3.933406  1.419101  \n57775 -26.512618 -57.904974      8  4.001899  1.346241  \n57776 -26.524580 -57.890832      8  3.903388  1.363433  \n\n[57777 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedHouseVal</th>\n      <th>is_generated</th>\n      <th>rot_15_x</th>\n      <th>rot_15_y</th>\n      <th>rot_30_x</th>\n      <th>rot_30_y</th>\n      <th>rot_45_x</th>\n      <th>place</th>\n      <th>pca_lat</th>\n      <th>pca_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.3859</td>\n      <td>15.0</td>\n      <td>3.827160</td>\n      <td>1.112100</td>\n      <td>1280.0</td>\n      <td>2.486989</td>\n      <td>34.60</td>\n      <td>-120.12</td>\n      <td>0.980</td>\n      <td>1</td>\n      <td>-107.071871</td>\n      <td>2.331690</td>\n      <td>-86.726972</td>\n      <td>-30.095521</td>\n      <td>-60.471772</td>\n      <td>11</td>\n      <td>-0.339172</td>\n      <td>-1.087686</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.7188</td>\n      <td>17.0</td>\n      <td>6.013373</td>\n      <td>1.054217</td>\n      <td>1504.0</td>\n      <td>3.813084</td>\n      <td>38.69</td>\n      <td>-121.22</td>\n      <td>0.946</td>\n      <td>1</td>\n      <td>-107.075820</td>\n      <td>5.997626</td>\n      <td>-85.634599</td>\n      <td>-27.103477</td>\n      <td>-58.357523</td>\n      <td>8</td>\n      <td>3.394240</td>\n      <td>0.912247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7750</td>\n      <td>27.0</td>\n      <td>6.535604</td>\n      <td>1.103175</td>\n      <td>1061.0</td>\n      <td>2.464602</td>\n      <td>34.71</td>\n      <td>-120.45</td>\n      <td>1.576</td>\n      <td>1</td>\n      <td>-107.362157</td>\n      <td>2.352531</td>\n      <td>-86.957760</td>\n      <td>-30.165258</td>\n      <td>-60.627335</td>\n      <td>11</td>\n      <td>-0.032996</td>\n      <td>-1.252781</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.4138</td>\n      <td>16.0</td>\n      <td>3.350203</td>\n      <td>0.965432</td>\n      <td>1255.0</td>\n      <td>2.089286</td>\n      <td>32.66</td>\n      <td>-117.09</td>\n      <td>1.336</td>\n      <td>1</td>\n      <td>-104.647225</td>\n      <td>1.242015</td>\n      <td>-85.072915</td>\n      <td>-30.260610</td>\n      <td>-59.701026</td>\n      <td>8</td>\n      <td>-3.828020</td>\n      <td>-0.208802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.7500</td>\n      <td>52.0</td>\n      <td>4.284404</td>\n      <td>1.069246</td>\n      <td>1793.0</td>\n      <td>1.604790</td>\n      <td>37.80</td>\n      <td>-122.41</td>\n      <td>4.500</td>\n      <td>1</td>\n      <td>-108.455620</td>\n      <td>4.829957</td>\n      <td>-87.110170</td>\n      <td>-28.469240</td>\n      <td>-59.828305</td>\n      <td>10</td>\n      <td>3.560861</td>\n      <td>-0.564383</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57772</th>\n      <td>1.5603</td>\n      <td>25.0</td>\n      <td>5.045455</td>\n      <td>1.133333</td>\n      <td>845.0</td>\n      <td>2.560606</td>\n      <td>39.48</td>\n      <td>-121.09</td>\n      <td>0.781</td>\n      <td>0</td>\n      <td>-106.745782</td>\n      <td>6.794353</td>\n      <td>-85.127016</td>\n      <td>-26.354317</td>\n      <td>-57.706984</td>\n      <td>8</td>\n      <td>3.880794</td>\n      <td>1.548066</td>\n    </tr>\n    <tr>\n      <th>57773</th>\n      <td>2.5568</td>\n      <td>18.0</td>\n      <td>6.114035</td>\n      <td>1.315789</td>\n      <td>356.0</td>\n      <td>3.122807</td>\n      <td>39.49</td>\n      <td>-121.21</td>\n      <td>0.771</td>\n      <td>0</td>\n      <td>-106.859105</td>\n      <td>6.772954</td>\n      <td>-85.225939</td>\n      <td>-26.405657</td>\n      <td>-57.784766</td>\n      <td>8</td>\n      <td>3.970272</td>\n      <td>1.467483</td>\n    </tr>\n    <tr>\n      <th>57774</th>\n      <td>1.7000</td>\n      <td>17.0</td>\n      <td>5.205543</td>\n      <td>1.120092</td>\n      <td>1007.0</td>\n      <td>2.325635</td>\n      <td>39.43</td>\n      <td>-121.22</td>\n      <td>0.923</td>\n      <td>0</td>\n      <td>-106.884294</td>\n      <td>6.712411</td>\n      <td>-85.264599</td>\n      <td>-26.462618</td>\n      <td>-57.834264</td>\n      <td>8</td>\n      <td>3.933406</td>\n      <td>1.419101</td>\n    </tr>\n    <tr>\n      <th>57775</th>\n      <td>1.8672</td>\n      <td>18.0</td>\n      <td>5.329513</td>\n      <td>1.171920</td>\n      <td>741.0</td>\n      <td>2.123209</td>\n      <td>39.43</td>\n      <td>-121.32</td>\n      <td>0.847</td>\n      <td>0</td>\n      <td>-106.980886</td>\n      <td>6.686529</td>\n      <td>-85.351202</td>\n      <td>-26.512618</td>\n      <td>-57.904974</td>\n      <td>8</td>\n      <td>4.001899</td>\n      <td>1.346241</td>\n    </tr>\n    <tr>\n      <th>57776</th>\n      <td>2.3886</td>\n      <td>16.0</td>\n      <td>5.254717</td>\n      <td>1.162264</td>\n      <td>1387.0</td>\n      <td>2.616981</td>\n      <td>39.37</td>\n      <td>-121.24</td>\n      <td>0.894</td>\n      <td>0</td>\n      <td>-106.919141</td>\n      <td>6.649279</td>\n      <td>-85.311920</td>\n      <td>-26.524580</td>\n      <td>-57.890832</td>\n      <td>8</td>\n      <td>3.903388</td>\n      <td>1.363433</td>\n    </tr>\n  </tbody>\n</table>\n<p>57777 rows Ã— 18 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "X = train.drop('MedHouseVal', axis=1)\n",
    "y_log = np.log1p(train[\"MedHouseVal\"].values)\n",
    "y = train['MedHouseVal']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "Scaler = StandardScaler()\n",
    "fin_train_scale = Scaler.fit_transform(X)\n",
    "fin_test_scale = Scaler.transform(test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "feature = []\n",
    "for col in X.columns:\n",
    "    feature.append(col)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "['MedInc',\n 'HouseAge',\n 'AveRooms',\n 'AveBedrms',\n 'Population',\n 'AveOccup',\n 'Latitude',\n 'Longitude',\n 'is_generated',\n 'rot_15_x',\n 'rot_15_y',\n 'rot_30_x',\n 'rot_30_y',\n 'rot_45_x',\n 'place',\n 'pca_lat',\n 'pca_lon']"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [98], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m k \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m75\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_index, val_index \u001B[38;5;129;01min\u001B[39;00m k\u001B[38;5;241m.\u001B[39msplit(train):\n\u001B[1;32m----> 3\u001B[0m     X_train, X_test \u001B[38;5;241m=\u001B[39m \u001B[43mfin_train_scale\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mloc[train_index], fin_train_scale[feature]\u001B[38;5;241m.\u001B[39mloc[val_index]\n\u001B[0;32m      4\u001B[0m     y_train, y_test \u001B[38;5;241m=\u001B[39m y[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMedHouseVal\u001B[39m\u001B[38;5;124m'\u001B[39m][train_index], y[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMedHouseVal\u001B[39m\u001B[38;5;124m'\u001B[39m][val_index]\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "k = KFold(n_splits=10, random_state=75, shuffle=True)\n",
    "for train_index, val_index in k.split(train):\n",
    "    X_train, X_test = train[feature].loc[train_index], train[feature].loc[val_index]\n",
    "    y_train, y_test = train['MedHouseVal'][train_index], train['MedHouseVal'][val_index]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fin_train_scale, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(max_depth=9,\n",
    "                    learning_rate=0.01,\n",
    "                    min_data_in_leaf=36,\n",
    "                    num_leaves=100,\n",
    "                    feature_fraction=0.8,\n",
    "                    bagging_fraction=0.89,\n",
    "                    bagging_freq=5,\n",
    "                    lambda_l2=28,\n",
    "                    seed=75,\n",
    "                    objective='regression',\n",
    "                    boosting_type='gbdt',\n",
    "                    device='gpu',\n",
    "                    gpu_platform_id=0,\n",
    "                    gpu_device_id=0,\n",
    "                    n_jobs=-1,\n",
    "                    metric='rmse',\n",
    "                    verbose=-1,\n",
    "                    n_estimators=7000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "lgb1 = LGBMRegressor(objective='regression', num_leaves=100, learning_rate=0.001, bagging_fraction=0.6,\n",
    "                     feature_fraction=0.6, bagging_frequency=6, bagging_seed=42, verbosity=-1, random_state=17,\n",
    "                     n_jobs=-1, metric='rmse', n_estimators=15000, seed=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's rmse: 0.614631\n",
      "[300]\tvalid_0's rmse: 0.540496\n",
      "[450]\tvalid_0's rmse: 0.522555\n",
      "[600]\tvalid_0's rmse: 0.51686\n",
      "[750]\tvalid_0's rmse: 0.514298\n",
      "[900]\tvalid_0's rmse: 0.512529\n",
      "[1050]\tvalid_0's rmse: 0.51134\n",
      "[1200]\tvalid_0's rmse: 0.510416\n",
      "[1350]\tvalid_0's rmse: 0.509622\n",
      "[1500]\tvalid_0's rmse: 0.509035\n",
      "[1650]\tvalid_0's rmse: 0.508774\n",
      "[1800]\tvalid_0's rmse: 0.508565\n",
      "[1950]\tvalid_0's rmse: 0.508252\n"
     ]
    },
    {
     "data": {
      "text/plain": "LGBMRegressor(bagging_fraction=0.89, bagging_freq=5, device='gpu',\n              feature_fraction=0.8, gpu_device_id=0, gpu_platform_id=0,\n              lambda_l2=28, learning_rate=0.01, max_depth=9, metric='rmse',\n              min_data_in_leaf=36, n_estimators=7000, num_leaves=100,\n              objective='regression', seed=75, verbose=-1)",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.89, bagging_freq=5, device=&#x27;gpu&#x27;,\n              feature_fraction=0.8, gpu_device_id=0, gpu_platform_id=0,\n              lambda_l2=28, learning_rate=0.01, max_depth=9, metric=&#x27;rmse&#x27;,\n              min_data_in_leaf=36, n_estimators=7000, num_leaves=100,\n              objective=&#x27;regression&#x27;, seed=75, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.89, bagging_freq=5, device=&#x27;gpu&#x27;,\n              feature_fraction=0.8, gpu_device_id=0, gpu_platform_id=0,\n              lambda_l2=28, learning_rate=0.01, max_depth=9, metric=&#x27;rmse&#x27;,\n              min_data_in_leaf=36, n_estimators=7000, num_leaves=100,\n              objective=&#x27;regression&#x27;, seed=75, verbose=-1)</pre></div></div></div></div></div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(X_train, y_train, eval_metric='rmse', eval_set=[(X_test, y_test)], early_stopping_rounds=30,\n",
    "        verbose=150)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's rmse: 1.04414\n",
      "[300]\tvalid_0's rmse: 0.952137\n",
      "[450]\tvalid_0's rmse: 0.874998\n",
      "[600]\tvalid_0's rmse: 0.809618\n",
      "[750]\tvalid_0's rmse: 0.755429\n",
      "[900]\tvalid_0's rmse: 0.710203\n",
      "[1050]\tvalid_0's rmse: 0.673152\n",
      "[1200]\tvalid_0's rmse: 0.643002\n",
      "[1350]\tvalid_0's rmse: 0.618779\n",
      "[1500]\tvalid_0's rmse: 0.598936\n",
      "[1650]\tvalid_0's rmse: 0.582873\n",
      "[1800]\tvalid_0's rmse: 0.569937\n",
      "[1950]\tvalid_0's rmse: 0.559477\n",
      "[2100]\tvalid_0's rmse: 0.551156\n",
      "[2250]\tvalid_0's rmse: 0.544359\n",
      "[2400]\tvalid_0's rmse: 0.53885\n",
      "[2550]\tvalid_0's rmse: 0.534361\n",
      "[2700]\tvalid_0's rmse: 0.530662\n",
      "[2850]\tvalid_0's rmse: 0.527618\n",
      "[3000]\tvalid_0's rmse: 0.525128\n",
      "[3150]\tvalid_0's rmse: 0.523017\n",
      "[3300]\tvalid_0's rmse: 0.521217\n",
      "[3450]\tvalid_0's rmse: 0.519751\n",
      "[3600]\tvalid_0's rmse: 0.518463\n",
      "[3750]\tvalid_0's rmse: 0.517331\n",
      "[3900]\tvalid_0's rmse: 0.516356\n",
      "[4050]\tvalid_0's rmse: 0.515449\n",
      "[4200]\tvalid_0's rmse: 0.514627\n",
      "[4350]\tvalid_0's rmse: 0.513949\n",
      "[4500]\tvalid_0's rmse: 0.513359\n",
      "[4650]\tvalid_0's rmse: 0.512842\n",
      "[4800]\tvalid_0's rmse: 0.51235\n",
      "[4950]\tvalid_0's rmse: 0.511884\n",
      "[5100]\tvalid_0's rmse: 0.51145\n",
      "[5250]\tvalid_0's rmse: 0.511047\n",
      "[5400]\tvalid_0's rmse: 0.510689\n",
      "[5550]\tvalid_0's rmse: 0.510354\n",
      "[5700]\tvalid_0's rmse: 0.510063\n",
      "[5850]\tvalid_0's rmse: 0.509789\n",
      "[6000]\tvalid_0's rmse: 0.50956\n",
      "[6150]\tvalid_0's rmse: 0.509346\n",
      "[6300]\tvalid_0's rmse: 0.509114\n",
      "[6450]\tvalid_0's rmse: 0.508904\n",
      "[6600]\tvalid_0's rmse: 0.508697\n",
      "[6750]\tvalid_0's rmse: 0.508505\n",
      "[6900]\tvalid_0's rmse: 0.508328\n",
      "[7050]\tvalid_0's rmse: 0.508149\n",
      "[7200]\tvalid_0's rmse: 0.508012\n",
      "[7350]\tvalid_0's rmse: 0.507846\n",
      "[7500]\tvalid_0's rmse: 0.507696\n",
      "[7650]\tvalid_0's rmse: 0.507572\n",
      "[7800]\tvalid_0's rmse: 0.507448\n",
      "[7950]\tvalid_0's rmse: 0.50734\n",
      "[8100]\tvalid_0's rmse: 0.507237\n",
      "[8250]\tvalid_0's rmse: 0.507147\n",
      "[8400]\tvalid_0's rmse: 0.507044\n",
      "[8550]\tvalid_0's rmse: 0.506968\n",
      "[8700]\tvalid_0's rmse: 0.506891\n",
      "[8850]\tvalid_0's rmse: 0.506825\n",
      "[9000]\tvalid_0's rmse: 0.506754\n",
      "[9150]\tvalid_0's rmse: 0.506684\n",
      "[9300]\tvalid_0's rmse: 0.506626\n",
      "[9450]\tvalid_0's rmse: 0.506563\n",
      "[9600]\tvalid_0's rmse: 0.506505\n",
      "[9750]\tvalid_0's rmse: 0.506447\n",
      "[9900]\tvalid_0's rmse: 0.506388\n",
      "[10050]\tvalid_0's rmse: 0.50633\n",
      "[10200]\tvalid_0's rmse: 0.506289\n",
      "[10350]\tvalid_0's rmse: 0.506221\n",
      "[10500]\tvalid_0's rmse: 0.506162\n",
      "[10650]\tvalid_0's rmse: 0.506112\n",
      "[10800]\tvalid_0's rmse: 0.506078\n",
      "[10950]\tvalid_0's rmse: 0.506032\n",
      "[11100]\tvalid_0's rmse: 0.505988\n",
      "[11250]\tvalid_0's rmse: 0.505936\n",
      "[11400]\tvalid_0's rmse: 0.505893\n",
      "[11550]\tvalid_0's rmse: 0.505853\n",
      "[11700]\tvalid_0's rmse: 0.505817\n",
      "[11850]\tvalid_0's rmse: 0.505785\n",
      "[12000]\tvalid_0's rmse: 0.505755\n",
      "[12150]\tvalid_0's rmse: 0.505721\n",
      "[12300]\tvalid_0's rmse: 0.505692\n",
      "[12450]\tvalid_0's rmse: 0.505665\n",
      "[12600]\tvalid_0's rmse: 0.505638\n"
     ]
    },
    {
     "data": {
      "text/plain": "LGBMRegressor(bagging_fraction=0.6, bagging_frequency=6, bagging_seed=42,\n              feature_fraction=0.6, learning_rate=0.001, metric='rmse',\n              n_estimators=15000, num_leaves=100, objective='regression',\n              random_state=17, seed=42, verbosity=-1)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.6, bagging_frequency=6, bagging_seed=42,\n              feature_fraction=0.6, learning_rate=0.001, metric=&#x27;rmse&#x27;,\n              n_estimators=15000, num_leaves=100, objective=&#x27;regression&#x27;,\n              random_state=17, seed=42, verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.6, bagging_frequency=6, bagging_seed=42,\n              feature_fraction=0.6, learning_rate=0.001, metric=&#x27;rmse&#x27;,\n              n_estimators=15000, num_leaves=100, objective=&#x27;regression&#x27;,\n              random_state=17, seed=42, verbosity=-1)</pre></div></div></div></div></div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb1.fit(X_train, y_train, eval_metric='rmse', eval_set=[(X_test, y_test)], early_stopping_rounds=30,\n",
    "         verbose=150)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "cat = CatBoostRegressor(depth=9,\n",
    "                        learning_rate=0.01,\n",
    "                        rsm=0.88,\n",
    "                        subsample=0.795,\n",
    "                        l2_leaf_reg=8,\n",
    "                        min_data_in_leaf=35,\n",
    "                        random_strength=0.63,\n",
    "                        use_best_model=True,\n",
    "                        task_type='CPU',\n",
    "                        bootstrap_type='Bernoulli',\n",
    "                        grow_policy='SymmetricTree',\n",
    "                        random_seed=75,\n",
    "                        loss_function='RMSE',\n",
    "                        eval_metric='RMSE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "cat1 = CatBoostRegressor(iterations=15000,\n",
    "                         learning_rate=0.003,\n",
    "                         depth=10,\n",
    "                         eval_metric='RMSE',\n",
    "                         random_seed=75,\n",
    "                         bagging_temperature=0.3,\n",
    "                         od_type='Iter',\n",
    "                         metric_period=50,\n",
    "                         od_wait=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1557854\ttest: 1.1523079\tbest: 1.1523079 (0)\ttotal: 146ms\tremaining: 36m 34s\n",
      "50:\tlearn: 1.0513553\ttest: 1.0472439\tbest: 1.0472439 (50)\ttotal: 4.35s\tremaining: 21m 16s\n",
      "100:\tlearn: 0.9646138\ttest: 0.9600564\tbest: 0.9600564 (100)\ttotal: 8.04s\tremaining: 19m 46s\n",
      "150:\tlearn: 0.8919139\ttest: 0.8870986\tbest: 0.8870986 (150)\ttotal: 11.5s\tremaining: 18m 48s\n",
      "200:\tlearn: 0.8319769\ttest: 0.8270404\tbest: 0.8270404 (200)\ttotal: 14.9s\tremaining: 18m 16s\n",
      "250:\tlearn: 0.7824394\ttest: 0.7773969\tbest: 0.7773969 (250)\ttotal: 18.2s\tremaining: 17m 50s\n",
      "300:\tlearn: 0.7414740\ttest: 0.7366264\tbest: 0.7366264 (300)\ttotal: 22s\tremaining: 17m 53s\n",
      "350:\tlearn: 0.7081529\ttest: 0.7034850\tbest: 0.7034850 (350)\ttotal: 25.5s\tremaining: 17m 45s\n",
      "400:\tlearn: 0.6806777\ttest: 0.6762672\tbest: 0.6762672 (400)\ttotal: 28.9s\tremaining: 17m 33s\n",
      "450:\tlearn: 0.6584338\ttest: 0.6542907\tbest: 0.6542907 (450)\ttotal: 32.3s\tremaining: 17m 20s\n",
      "500:\tlearn: 0.6399216\ttest: 0.6361228\tbest: 0.6361228 (500)\ttotal: 35.9s\tremaining: 17m 18s\n",
      "550:\tlearn: 0.6248078\ttest: 0.6213893\tbest: 0.6213893 (550)\ttotal: 39.5s\tremaining: 17m 16s\n",
      "600:\tlearn: 0.6121540\ttest: 0.6090484\tbest: 0.6090484 (600)\ttotal: 43s\tremaining: 17m 11s\n",
      "650:\tlearn: 0.6017080\ttest: 0.5989984\tbest: 0.5989984 (650)\ttotal: 48.2s\tremaining: 17m 42s\n",
      "700:\tlearn: 0.5929018\ttest: 0.5906639\tbest: 0.5906639 (700)\ttotal: 52.4s\tremaining: 17m 48s\n",
      "750:\tlearn: 0.5855471\ttest: 0.5838046\tbest: 0.5838046 (750)\ttotal: 56.3s\tremaining: 17m 47s\n",
      "800:\tlearn: 0.5792388\ttest: 0.5779652\tbest: 0.5779652 (800)\ttotal: 59.8s\tremaining: 17m 40s\n",
      "850:\tlearn: 0.5739384\ttest: 0.5730841\tbest: 0.5730841 (850)\ttotal: 1m 3s\tremaining: 17m 29s\n",
      "900:\tlearn: 0.5693398\ttest: 0.5689853\tbest: 0.5689853 (900)\ttotal: 1m 6s\tremaining: 17m 21s\n",
      "950:\tlearn: 0.5652680\ttest: 0.5653592\tbest: 0.5653592 (950)\ttotal: 1m 9s\tremaining: 17m 12s\n",
      "1000:\tlearn: 0.5615716\ttest: 0.5620445\tbest: 0.5620445 (1000)\ttotal: 1m 13s\tremaining: 17m 3s\n",
      "1050:\tlearn: 0.5583778\ttest: 0.5592906\tbest: 0.5592906 (1050)\ttotal: 1m 16s\tremaining: 16m 54s\n",
      "1100:\tlearn: 0.5554734\ttest: 0.5568556\tbest: 0.5568556 (1100)\ttotal: 1m 19s\tremaining: 16m 46s\n",
      "1150:\tlearn: 0.5528100\ttest: 0.5546208\tbest: 0.5546208 (1150)\ttotal: 1m 22s\tremaining: 16m 38s\n",
      "1200:\tlearn: 0.5503516\ttest: 0.5526339\tbest: 0.5526339 (1200)\ttotal: 1m 26s\tremaining: 16m 31s\n",
      "1250:\tlearn: 0.5481199\ttest: 0.5508080\tbest: 0.5508080 (1250)\ttotal: 1m 29s\tremaining: 16m 23s\n",
      "1300:\tlearn: 0.5460889\ttest: 0.5491599\tbest: 0.5491599 (1300)\ttotal: 1m 32s\tremaining: 16m 16s\n",
      "1350:\tlearn: 0.5440240\ttest: 0.5475263\tbest: 0.5475263 (1350)\ttotal: 1m 36s\tremaining: 16m 10s\n",
      "1400:\tlearn: 0.5422086\ttest: 0.5461456\tbest: 0.5461456 (1400)\ttotal: 1m 39s\tremaining: 16m 3s\n",
      "1450:\tlearn: 0.5403658\ttest: 0.5447106\tbest: 0.5447106 (1450)\ttotal: 1m 42s\tremaining: 15m 57s\n",
      "1500:\tlearn: 0.5387793\ttest: 0.5435201\tbest: 0.5435201 (1500)\ttotal: 1m 45s\tremaining: 15m 51s\n",
      "1550:\tlearn: 0.5372820\ttest: 0.5424824\tbest: 0.5424824 (1550)\ttotal: 1m 49s\tremaining: 15m 45s\n",
      "1600:\tlearn: 0.5357527\ttest: 0.5414176\tbest: 0.5414176 (1600)\ttotal: 1m 52s\tremaining: 15m 40s\n",
      "1650:\tlearn: 0.5343044\ttest: 0.5404414\tbest: 0.5404414 (1650)\ttotal: 1m 55s\tremaining: 15m 34s\n",
      "1700:\tlearn: 0.5329452\ttest: 0.5395831\tbest: 0.5395831 (1700)\ttotal: 1m 58s\tremaining: 15m 29s\n",
      "1750:\tlearn: 0.5315924\ttest: 0.5386736\tbest: 0.5386736 (1750)\ttotal: 2m 2s\tremaining: 15m 23s\n",
      "1800:\tlearn: 0.5302270\ttest: 0.5378725\tbest: 0.5378725 (1800)\ttotal: 2m 5s\tremaining: 15m 18s\n",
      "1850:\tlearn: 0.5289689\ttest: 0.5371262\tbest: 0.5371262 (1850)\ttotal: 2m 8s\tremaining: 15m 13s\n",
      "1900:\tlearn: 0.5277618\ttest: 0.5363867\tbest: 0.5363867 (1900)\ttotal: 2m 11s\tremaining: 15m 8s\n",
      "1950:\tlearn: 0.5265598\ttest: 0.5357552\tbest: 0.5357552 (1950)\ttotal: 2m 15s\tremaining: 15m 3s\n",
      "2000:\tlearn: 0.5253562\ttest: 0.5350648\tbest: 0.5350648 (2000)\ttotal: 2m 18s\tremaining: 14m 59s\n",
      "2050:\tlearn: 0.5241953\ttest: 0.5344290\tbest: 0.5344290 (2050)\ttotal: 2m 21s\tremaining: 14m 55s\n",
      "2100:\tlearn: 0.5230907\ttest: 0.5338173\tbest: 0.5338173 (2100)\ttotal: 2m 25s\tremaining: 14m 50s\n",
      "2150:\tlearn: 0.5219677\ttest: 0.5332778\tbest: 0.5332778 (2150)\ttotal: 2m 28s\tremaining: 14m 46s\n",
      "2200:\tlearn: 0.5208613\ttest: 0.5327507\tbest: 0.5327507 (2200)\ttotal: 2m 31s\tremaining: 14m 41s\n",
      "2250:\tlearn: 0.5198502\ttest: 0.5322154\tbest: 0.5322154 (2250)\ttotal: 2m 34s\tremaining: 14m 37s\n",
      "2300:\tlearn: 0.5187527\ttest: 0.5317237\tbest: 0.5317237 (2300)\ttotal: 2m 38s\tremaining: 14m 32s\n",
      "2350:\tlearn: 0.5177212\ttest: 0.5312144\tbest: 0.5312144 (2350)\ttotal: 2m 41s\tremaining: 14m 28s\n",
      "2400:\tlearn: 0.5166825\ttest: 0.5307986\tbest: 0.5307986 (2400)\ttotal: 2m 44s\tremaining: 14m 24s\n",
      "2450:\tlearn: 0.5156875\ttest: 0.5303811\tbest: 0.5303811 (2450)\ttotal: 2m 47s\tremaining: 14m 19s\n",
      "2500:\tlearn: 0.5147207\ttest: 0.5299401\tbest: 0.5299401 (2500)\ttotal: 2m 51s\tremaining: 14m 15s\n",
      "2550:\tlearn: 0.5137118\ttest: 0.5295241\tbest: 0.5295241 (2550)\ttotal: 2m 54s\tremaining: 14m 11s\n",
      "2600:\tlearn: 0.5127359\ttest: 0.5290920\tbest: 0.5290920 (2600)\ttotal: 2m 57s\tremaining: 14m 7s\n",
      "2650:\tlearn: 0.5118047\ttest: 0.5286680\tbest: 0.5286680 (2650)\ttotal: 3m\tremaining: 14m 2s\n",
      "2700:\tlearn: 0.5108971\ttest: 0.5282820\tbest: 0.5282820 (2700)\ttotal: 3m 4s\tremaining: 13m 58s\n",
      "2750:\tlearn: 0.5099743\ttest: 0.5278712\tbest: 0.5278712 (2750)\ttotal: 3m 7s\tremaining: 13m 54s\n",
      "2800:\tlearn: 0.5090263\ttest: 0.5275145\tbest: 0.5275145 (2800)\ttotal: 3m 10s\tremaining: 13m 50s\n",
      "2850:\tlearn: 0.5080831\ttest: 0.5271079\tbest: 0.5271079 (2850)\ttotal: 3m 14s\tremaining: 13m 46s\n",
      "2900:\tlearn: 0.5071739\ttest: 0.5267728\tbest: 0.5267728 (2900)\ttotal: 3m 17s\tremaining: 13m 42s\n",
      "2950:\tlearn: 0.5062816\ttest: 0.5264174\tbest: 0.5264174 (2950)\ttotal: 3m 20s\tremaining: 13m 38s\n",
      "3000:\tlearn: 0.5054592\ttest: 0.5260713\tbest: 0.5260713 (3000)\ttotal: 3m 23s\tremaining: 13m 34s\n",
      "3050:\tlearn: 0.5045287\ttest: 0.5257643\tbest: 0.5257643 (3050)\ttotal: 3m 27s\tremaining: 13m 31s\n",
      "3100:\tlearn: 0.5037049\ttest: 0.5254421\tbest: 0.5254421 (3100)\ttotal: 3m 30s\tremaining: 13m 27s\n",
      "3150:\tlearn: 0.5028287\ttest: 0.5251174\tbest: 0.5251174 (3150)\ttotal: 3m 33s\tremaining: 13m 23s\n",
      "3200:\tlearn: 0.5020548\ttest: 0.5248422\tbest: 0.5248422 (3200)\ttotal: 3m 36s\tremaining: 13m 19s\n",
      "3250:\tlearn: 0.5011590\ttest: 0.5245294\tbest: 0.5245294 (3250)\ttotal: 3m 40s\tremaining: 13m 16s\n",
      "3300:\tlearn: 0.5002710\ttest: 0.5242292\tbest: 0.5242292 (3300)\ttotal: 3m 43s\tremaining: 13m 13s\n",
      "3350:\tlearn: 0.4994929\ttest: 0.5239827\tbest: 0.5239827 (3350)\ttotal: 3m 47s\tremaining: 13m 9s\n",
      "3400:\tlearn: 0.4986991\ttest: 0.5237120\tbest: 0.5237120 (3400)\ttotal: 3m 50s\tremaining: 13m 5s\n",
      "3450:\tlearn: 0.4978448\ttest: 0.5233974\tbest: 0.5233974 (3450)\ttotal: 3m 53s\tremaining: 13m 2s\n",
      "3500:\tlearn: 0.4970037\ttest: 0.5231113\tbest: 0.5231113 (3500)\ttotal: 3m 57s\tremaining: 12m 58s\n",
      "3550:\tlearn: 0.4962104\ttest: 0.5228662\tbest: 0.5228662 (3550)\ttotal: 4m\tremaining: 12m 54s\n",
      "3600:\tlearn: 0.4953716\ttest: 0.5226064\tbest: 0.5226064 (3600)\ttotal: 4m 3s\tremaining: 12m 51s\n",
      "3650:\tlearn: 0.4945527\ttest: 0.5224000\tbest: 0.5224000 (3650)\ttotal: 4m 6s\tremaining: 12m 47s\n",
      "3700:\tlearn: 0.4937230\ttest: 0.5221434\tbest: 0.5221434 (3700)\ttotal: 4m 10s\tremaining: 12m 43s\n",
      "3750:\tlearn: 0.4929061\ttest: 0.5219333\tbest: 0.5219333 (3750)\ttotal: 4m 13s\tremaining: 12m 40s\n",
      "3800:\tlearn: 0.4920841\ttest: 0.5216823\tbest: 0.5216823 (3800)\ttotal: 4m 16s\tremaining: 12m 36s\n",
      "3850:\tlearn: 0.4912646\ttest: 0.5214540\tbest: 0.5214540 (3850)\ttotal: 4m 19s\tremaining: 12m 32s\n",
      "3900:\tlearn: 0.4904844\ttest: 0.5212518\tbest: 0.5212518 (3900)\ttotal: 4m 23s\tremaining: 12m 28s\n",
      "3950:\tlearn: 0.4897085\ttest: 0.5210743\tbest: 0.5210743 (3950)\ttotal: 4m 26s\tremaining: 12m 25s\n",
      "4000:\tlearn: 0.4889038\ttest: 0.5209116\tbest: 0.5209116 (4000)\ttotal: 4m 29s\tremaining: 12m 21s\n",
      "4050:\tlearn: 0.4881014\ttest: 0.5207258\tbest: 0.5207258 (4050)\ttotal: 4m 33s\tremaining: 12m 17s\n",
      "4100:\tlearn: 0.4873362\ttest: 0.5205527\tbest: 0.5205527 (4100)\ttotal: 4m 36s\tremaining: 12m 14s\n",
      "4150:\tlearn: 0.4865856\ttest: 0.5203640\tbest: 0.5203640 (4150)\ttotal: 4m 39s\tremaining: 12m 10s\n",
      "4200:\tlearn: 0.4858002\ttest: 0.5201827\tbest: 0.5201827 (4200)\ttotal: 4m 43s\tremaining: 12m 8s\n",
      "4250:\tlearn: 0.4849990\ttest: 0.5199952\tbest: 0.5199952 (4250)\ttotal: 4m 47s\tremaining: 12m 6s\n",
      "4300:\tlearn: 0.4842329\ttest: 0.5198136\tbest: 0.5198136 (4300)\ttotal: 4m 51s\tremaining: 12m 5s\n",
      "4350:\tlearn: 0.4834487\ttest: 0.5196401\tbest: 0.5196401 (4350)\ttotal: 4m 56s\tremaining: 12m 5s\n",
      "4400:\tlearn: 0.4827113\ttest: 0.5194867\tbest: 0.5194867 (4400)\ttotal: 5m\tremaining: 12m 3s\n",
      "4450:\tlearn: 0.4819075\ttest: 0.5193573\tbest: 0.5193569 (4449)\ttotal: 5m 4s\tremaining: 12m 2s\n",
      "4500:\tlearn: 0.4811443\ttest: 0.5192298\tbest: 0.5192298 (4500)\ttotal: 5m 8s\tremaining: 12m\n",
      "4550:\tlearn: 0.4803414\ttest: 0.5190608\tbest: 0.5190608 (4550)\ttotal: 5m 13s\tremaining: 11m 58s\n",
      "4600:\tlearn: 0.4795835\ttest: 0.5189133\tbest: 0.5189133 (4600)\ttotal: 5m 17s\tremaining: 11m 57s\n",
      "4650:\tlearn: 0.4788091\ttest: 0.5187742\tbest: 0.5187742 (4650)\ttotal: 5m 21s\tremaining: 11m 55s\n",
      "4700:\tlearn: 0.4780534\ttest: 0.5186582\tbest: 0.5186582 (4700)\ttotal: 5m 25s\tremaining: 11m 53s\n",
      "4750:\tlearn: 0.4772718\ttest: 0.5185055\tbest: 0.5185055 (4750)\ttotal: 5m 29s\tremaining: 11m 50s\n",
      "4800:\tlearn: 0.4765556\ttest: 0.5183716\tbest: 0.5183716 (4800)\ttotal: 5m 32s\tremaining: 11m 46s\n",
      "4850:\tlearn: 0.4758329\ttest: 0.5182383\tbest: 0.5182383 (4850)\ttotal: 5m 35s\tremaining: 11m 42s\n",
      "4900:\tlearn: 0.4751151\ttest: 0.5181088\tbest: 0.5181088 (4900)\ttotal: 5m 38s\tremaining: 11m 38s\n",
      "4950:\tlearn: 0.4743899\ttest: 0.5179596\tbest: 0.5179596 (4950)\ttotal: 5m 41s\tremaining: 11m 34s\n",
      "5000:\tlearn: 0.4736786\ttest: 0.5178336\tbest: 0.5178336 (5000)\ttotal: 5m 45s\tremaining: 11m 29s\n",
      "5050:\tlearn: 0.4729375\ttest: 0.5177076\tbest: 0.5177076 (5050)\ttotal: 5m 48s\tremaining: 11m 26s\n",
      "5100:\tlearn: 0.4722510\ttest: 0.5175752\tbest: 0.5175752 (5100)\ttotal: 5m 51s\tremaining: 11m 22s\n",
      "5150:\tlearn: 0.4716261\ttest: 0.5174477\tbest: 0.5174477 (5150)\ttotal: 5m 54s\tremaining: 11m 18s\n",
      "5200:\tlearn: 0.4709406\ttest: 0.5173098\tbest: 0.5173097 (5199)\ttotal: 5m 57s\tremaining: 11m 14s\n",
      "5250:\tlearn: 0.4702705\ttest: 0.5171971\tbest: 0.5171956 (5249)\ttotal: 6m 1s\tremaining: 11m 10s\n",
      "5300:\tlearn: 0.4696001\ttest: 0.5170488\tbest: 0.5170488 (5300)\ttotal: 6m 4s\tremaining: 11m 7s\n",
      "5350:\tlearn: 0.4689208\ttest: 0.5169172\tbest: 0.5169172 (5350)\ttotal: 6m 8s\tremaining: 11m 4s\n",
      "5400:\tlearn: 0.4682718\ttest: 0.5167959\tbest: 0.5167959 (5400)\ttotal: 6m 11s\tremaining: 11m\n",
      "5450:\tlearn: 0.4675630\ttest: 0.5166888\tbest: 0.5166888 (5450)\ttotal: 6m 14s\tremaining: 10m 56s\n",
      "5500:\tlearn: 0.4668939\ttest: 0.5165706\tbest: 0.5165706 (5500)\ttotal: 6m 18s\tremaining: 10m 53s\n",
      "5550:\tlearn: 0.4662994\ttest: 0.5164544\tbest: 0.5164544 (5550)\ttotal: 6m 21s\tremaining: 10m 49s\n",
      "5600:\tlearn: 0.4656201\ttest: 0.5163388\tbest: 0.5163388 (5600)\ttotal: 6m 24s\tremaining: 10m 45s\n",
      "5650:\tlearn: 0.4649570\ttest: 0.5161921\tbest: 0.5161921 (5650)\ttotal: 6m 27s\tremaining: 10m 41s\n",
      "5700:\tlearn: 0.4643121\ttest: 0.5161047\tbest: 0.5161047 (5700)\ttotal: 6m 30s\tremaining: 10m 37s\n",
      "5750:\tlearn: 0.4636942\ttest: 0.5160257\tbest: 0.5160257 (5748)\ttotal: 6m 34s\tremaining: 10m 33s\n",
      "5800:\tlearn: 0.4630348\ttest: 0.5158995\tbest: 0.5158995 (5800)\ttotal: 6m 37s\tremaining: 10m 29s\n",
      "5850:\tlearn: 0.4624284\ttest: 0.5157744\tbest: 0.5157744 (5850)\ttotal: 6m 40s\tremaining: 10m 26s\n",
      "5900:\tlearn: 0.4618034\ttest: 0.5156629\tbest: 0.5156629 (5900)\ttotal: 6m 43s\tremaining: 10m 22s\n",
      "5950:\tlearn: 0.4611230\ttest: 0.5155395\tbest: 0.5155395 (5950)\ttotal: 6m 46s\tremaining: 10m 18s\n",
      "6000:\tlearn: 0.4605102\ttest: 0.5154393\tbest: 0.5154393 (6000)\ttotal: 6m 50s\tremaining: 10m 14s\n",
      "6050:\tlearn: 0.4599083\ttest: 0.5153448\tbest: 0.5153448 (6050)\ttotal: 6m 53s\tremaining: 10m 11s\n",
      "6100:\tlearn: 0.4593323\ttest: 0.5152323\tbest: 0.5152323 (6100)\ttotal: 6m 56s\tremaining: 10m 7s\n",
      "6150:\tlearn: 0.4587285\ttest: 0.5151322\tbest: 0.5151322 (6150)\ttotal: 6m 59s\tremaining: 10m 3s\n",
      "6200:\tlearn: 0.4581487\ttest: 0.5150215\tbest: 0.5150215 (6200)\ttotal: 7m 2s\tremaining: 10m\n",
      "6250:\tlearn: 0.4576149\ttest: 0.5149370\tbest: 0.5149370 (6250)\ttotal: 7m 6s\tremaining: 9m 56s\n",
      "6300:\tlearn: 0.4569483\ttest: 0.5148408\tbest: 0.5148408 (6300)\ttotal: 7m 9s\tremaining: 9m 53s\n",
      "6350:\tlearn: 0.4563366\ttest: 0.5147570\tbest: 0.5147570 (6350)\ttotal: 7m 13s\tremaining: 9m 50s\n",
      "6400:\tlearn: 0.4557493\ttest: 0.5146623\tbest: 0.5146623 (6400)\ttotal: 7m 16s\tremaining: 9m 46s\n",
      "6450:\tlearn: 0.4551615\ttest: 0.5145905\tbest: 0.5145884 (6448)\ttotal: 7m 19s\tremaining: 9m 42s\n",
      "6500:\tlearn: 0.4545869\ttest: 0.5145190\tbest: 0.5145190 (6500)\ttotal: 7m 23s\tremaining: 9m 40s\n",
      "6550:\tlearn: 0.4540094\ttest: 0.5144374\tbest: 0.5144374 (6550)\ttotal: 7m 27s\tremaining: 9m 36s\n",
      "6600:\tlearn: 0.4534404\ttest: 0.5143725\tbest: 0.5143711 (6598)\ttotal: 7m 30s\tremaining: 9m 33s\n",
      "6650:\tlearn: 0.4528789\ttest: 0.5142985\tbest: 0.5142985 (6650)\ttotal: 7m 34s\tremaining: 9m 29s\n",
      "6700:\tlearn: 0.4522754\ttest: 0.5142438\tbest: 0.5142438 (6700)\ttotal: 7m 37s\tremaining: 9m 26s\n",
      "6750:\tlearn: 0.4516928\ttest: 0.5141617\tbest: 0.5141617 (6750)\ttotal: 7m 40s\tremaining: 9m 22s\n",
      "6800:\tlearn: 0.4511286\ttest: 0.5140891\tbest: 0.5140891 (6800)\ttotal: 7m 43s\tremaining: 9m 19s\n",
      "6850:\tlearn: 0.4505784\ttest: 0.5140089\tbest: 0.5140073 (6849)\ttotal: 7m 47s\tremaining: 9m 15s\n",
      "6900:\tlearn: 0.4500274\ttest: 0.5139417\tbest: 0.5139417 (6900)\ttotal: 7m 50s\tremaining: 9m 11s\n",
      "6950:\tlearn: 0.4494648\ttest: 0.5138782\tbest: 0.5138782 (6950)\ttotal: 7m 53s\tremaining: 9m 8s\n",
      "7000:\tlearn: 0.4489283\ttest: 0.5138225\tbest: 0.5138225 (7000)\ttotal: 7m 56s\tremaining: 9m 4s\n",
      "7050:\tlearn: 0.4483856\ttest: 0.5137333\tbest: 0.5137333 (7050)\ttotal: 7m 59s\tremaining: 9m 1s\n",
      "7100:\tlearn: 0.4478439\ttest: 0.5136581\tbest: 0.5136581 (7100)\ttotal: 8m 3s\tremaining: 8m 57s\n",
      "7150:\tlearn: 0.4472602\ttest: 0.5135724\tbest: 0.5135724 (7150)\ttotal: 8m 6s\tremaining: 8m 53s\n",
      "7200:\tlearn: 0.4466877\ttest: 0.5135033\tbest: 0.5135033 (7200)\ttotal: 8m 9s\tremaining: 8m 50s\n",
      "7250:\tlearn: 0.4461296\ttest: 0.5134383\tbest: 0.5134381 (7248)\ttotal: 8m 12s\tremaining: 8m 46s\n",
      "7300:\tlearn: 0.4455839\ttest: 0.5133643\tbest: 0.5133643 (7300)\ttotal: 8m 16s\tremaining: 8m 43s\n",
      "7350:\tlearn: 0.4450537\ttest: 0.5133061\tbest: 0.5133061 (7350)\ttotal: 8m 19s\tremaining: 8m 39s\n",
      "7400:\tlearn: 0.4445370\ttest: 0.5132484\tbest: 0.5132484 (7400)\ttotal: 8m 22s\tremaining: 8m 36s\n",
      "7450:\tlearn: 0.4439855\ttest: 0.5131810\tbest: 0.5131810 (7450)\ttotal: 8m 26s\tremaining: 8m 32s\n",
      "7500:\tlearn: 0.4434903\ttest: 0.5131265\tbest: 0.5131260 (7497)\ttotal: 8m 29s\tremaining: 8m 29s\n",
      "7550:\tlearn: 0.4429522\ttest: 0.5130804\tbest: 0.5130804 (7550)\ttotal: 8m 32s\tremaining: 8m 25s\n",
      "7600:\tlearn: 0.4424505\ttest: 0.5130027\tbest: 0.5130021 (7599)\ttotal: 8m 35s\tremaining: 8m 22s\n",
      "7650:\tlearn: 0.4419328\ttest: 0.5129575\tbest: 0.5129575 (7650)\ttotal: 8m 39s\tremaining: 8m 18s\n",
      "7700:\tlearn: 0.4414284\ttest: 0.5129022\tbest: 0.5129022 (7700)\ttotal: 8m 42s\tremaining: 8m 15s\n",
      "7750:\tlearn: 0.4409221\ttest: 0.5128436\tbest: 0.5128436 (7750)\ttotal: 8m 45s\tremaining: 8m 11s\n",
      "7800:\tlearn: 0.4404128\ttest: 0.5127925\tbest: 0.5127917 (7799)\ttotal: 8m 48s\tremaining: 8m 8s\n",
      "7850:\tlearn: 0.4399007\ttest: 0.5127264\tbest: 0.5127256 (7849)\ttotal: 8m 52s\tremaining: 8m 4s\n",
      "7900:\tlearn: 0.4393883\ttest: 0.5126860\tbest: 0.5126860 (7900)\ttotal: 8m 55s\tremaining: 8m 1s\n",
      "7950:\tlearn: 0.4388533\ttest: 0.5126235\tbest: 0.5126234 (7949)\ttotal: 8m 58s\tremaining: 7m 57s\n",
      "8000:\tlearn: 0.4383491\ttest: 0.5125802\tbest: 0.5125802 (8000)\ttotal: 9m 2s\tremaining: 7m 54s\n",
      "8050:\tlearn: 0.4378292\ttest: 0.5125253\tbest: 0.5125253 (8050)\ttotal: 9m 5s\tremaining: 7m 50s\n",
      "8100:\tlearn: 0.4373130\ttest: 0.5124726\tbest: 0.5124704 (8099)\ttotal: 9m 8s\tremaining: 7m 47s\n",
      "8150:\tlearn: 0.4367948\ttest: 0.5124217\tbest: 0.5124217 (8150)\ttotal: 9m 12s\tremaining: 7m 43s\n",
      "8200:\tlearn: 0.4362845\ttest: 0.5123657\tbest: 0.5123657 (8200)\ttotal: 9m 15s\tremaining: 7m 40s\n",
      "8250:\tlearn: 0.4358180\ttest: 0.5123175\tbest: 0.5123175 (8250)\ttotal: 9m 18s\tremaining: 7m 36s\n",
      "8300:\tlearn: 0.4353202\ttest: 0.5122696\tbest: 0.5122696 (8300)\ttotal: 9m 21s\tremaining: 7m 33s\n",
      "8350:\tlearn: 0.4348406\ttest: 0.5122444\tbest: 0.5122425 (8349)\ttotal: 9m 24s\tremaining: 7m 29s\n",
      "8400:\tlearn: 0.4343305\ttest: 0.5122027\tbest: 0.5122027 (8400)\ttotal: 9m 28s\tremaining: 7m 26s\n",
      "8450:\tlearn: 0.4338076\ttest: 0.5121360\tbest: 0.5121354 (8448)\ttotal: 9m 31s\tremaining: 7m 22s\n",
      "8500:\tlearn: 0.4333483\ttest: 0.5121050\tbest: 0.5121043 (8487)\ttotal: 9m 34s\tremaining: 7m 19s\n",
      "8550:\tlearn: 0.4328560\ttest: 0.5120565\tbest: 0.5120565 (8550)\ttotal: 9m 37s\tremaining: 7m 15s\n",
      "8600:\tlearn: 0.4323439\ttest: 0.5120291\tbest: 0.5120285 (8599)\ttotal: 9m 41s\tremaining: 7m 12s\n",
      "8650:\tlearn: 0.4319021\ttest: 0.5120010\tbest: 0.5120010 (8650)\ttotal: 9m 45s\tremaining: 7m 9s\n",
      "8700:\tlearn: 0.4314111\ttest: 0.5119609\tbest: 0.5119609 (8700)\ttotal: 9m 48s\tremaining: 7m 6s\n",
      "8750:\tlearn: 0.4309192\ttest: 0.5119134\tbest: 0.5119134 (8750)\ttotal: 9m 52s\tremaining: 7m 2s\n",
      "8800:\tlearn: 0.4304461\ttest: 0.5118844\tbest: 0.5118844 (8800)\ttotal: 9m 55s\tremaining: 6m 59s\n",
      "8850:\tlearn: 0.4299527\ttest: 0.5118597\tbest: 0.5118597 (8850)\ttotal: 9m 59s\tremaining: 6m 56s\n",
      "8900:\tlearn: 0.4294489\ttest: 0.5118194\tbest: 0.5118194 (8900)\ttotal: 10m 2s\tremaining: 6m 52s\n",
      "8950:\tlearn: 0.4289611\ttest: 0.5117794\tbest: 0.5117768 (8945)\ttotal: 10m 5s\tremaining: 6m 49s\n",
      "9000:\tlearn: 0.4284601\ttest: 0.5117369\tbest: 0.5117369 (9000)\ttotal: 10m 9s\tremaining: 6m 46s\n",
      "9050:\tlearn: 0.4279753\ttest: 0.5116929\tbest: 0.5116929 (9049)\ttotal: 10m 12s\tremaining: 6m 42s\n",
      "9100:\tlearn: 0.4274920\ttest: 0.5116561\tbest: 0.5116561 (9100)\ttotal: 10m 15s\tremaining: 6m 39s\n",
      "9150:\tlearn: 0.4270248\ttest: 0.5116328\tbest: 0.5116328 (9147)\ttotal: 10m 19s\tremaining: 6m 35s\n",
      "9200:\tlearn: 0.4265798\ttest: 0.5115912\tbest: 0.5115912 (9200)\ttotal: 10m 22s\tremaining: 6m 32s\n",
      "9250:\tlearn: 0.4261393\ttest: 0.5115621\tbest: 0.5115621 (9250)\ttotal: 10m 26s\tremaining: 6m 29s\n",
      "9300:\tlearn: 0.4256883\ttest: 0.5115245\tbest: 0.5115220 (9297)\ttotal: 10m 30s\tremaining: 6m 26s\n",
      "9350:\tlearn: 0.4252136\ttest: 0.5114956\tbest: 0.5114928 (9348)\ttotal: 10m 33s\tremaining: 6m 22s\n",
      "9400:\tlearn: 0.4247741\ttest: 0.5114546\tbest: 0.5114546 (9400)\ttotal: 10m 36s\tremaining: 6m 19s\n",
      "9450:\tlearn: 0.4242964\ttest: 0.5114218\tbest: 0.5114215 (9446)\ttotal: 10m 40s\tremaining: 6m 16s\n",
      "9500:\tlearn: 0.4238186\ttest: 0.5114027\tbest: 0.5114027 (9500)\ttotal: 10m 44s\tremaining: 6m 12s\n",
      "9550:\tlearn: 0.4233846\ttest: 0.5113794\tbest: 0.5113794 (9550)\ttotal: 10m 47s\tremaining: 6m 9s\n",
      "9600:\tlearn: 0.4229225\ttest: 0.5113467\tbest: 0.5113455 (9599)\ttotal: 10m 51s\tremaining: 6m 6s\n",
      "9650:\tlearn: 0.4224853\ttest: 0.5113219\tbest: 0.5113219 (9650)\ttotal: 10m 54s\tremaining: 6m 2s\n",
      "9700:\tlearn: 0.4220420\ttest: 0.5112780\tbest: 0.5112765 (9697)\ttotal: 10m 57s\tremaining: 5m 59s\n",
      "9750:\tlearn: 0.4215506\ttest: 0.5112579\tbest: 0.5112578 (9744)\ttotal: 11m 1s\tremaining: 5m 55s\n",
      "9800:\tlearn: 0.4211029\ttest: 0.5112353\tbest: 0.5112351 (9798)\ttotal: 11m 4s\tremaining: 5m 52s\n",
      "9850:\tlearn: 0.4206508\ttest: 0.5112111\tbest: 0.5112111 (9850)\ttotal: 11m 7s\tremaining: 5m 49s\n",
      "9900:\tlearn: 0.4201787\ttest: 0.5111778\tbest: 0.5111762 (9897)\ttotal: 11m 11s\tremaining: 5m 45s\n",
      "9950:\tlearn: 0.4197188\ttest: 0.5111440\tbest: 0.5111440 (9950)\ttotal: 11m 15s\tremaining: 5m 42s\n",
      "10000:\tlearn: 0.4192656\ttest: 0.5111315\tbest: 0.5111293 (9998)\ttotal: 11m 19s\tremaining: 5m 39s\n",
      "10050:\tlearn: 0.4188176\ttest: 0.5111089\tbest: 0.5111089 (10050)\ttotal: 11m 22s\tremaining: 5m 36s\n",
      "10100:\tlearn: 0.4183979\ttest: 0.5110700\tbest: 0.5110700 (10100)\ttotal: 11m 27s\tremaining: 5m 33s\n",
      "10150:\tlearn: 0.4179150\ttest: 0.5110475\tbest: 0.5110449 (10144)\ttotal: 11m 31s\tremaining: 5m 30s\n",
      "10200:\tlearn: 0.4174694\ttest: 0.5110189\tbest: 0.5110189 (10200)\ttotal: 11m 34s\tremaining: 5m 26s\n",
      "10250:\tlearn: 0.4170621\ttest: 0.5109976\tbest: 0.5109956 (10244)\ttotal: 11m 38s\tremaining: 5m 23s\n",
      "10300:\tlearn: 0.4166103\ttest: 0.5109601\tbest: 0.5109586 (10297)\ttotal: 11m 42s\tremaining: 5m 20s\n",
      "10350:\tlearn: 0.4161731\ttest: 0.5109365\tbest: 0.5109365 (10350)\ttotal: 11m 46s\tremaining: 5m 17s\n",
      "10400:\tlearn: 0.4157616\ttest: 0.5109248\tbest: 0.5109248 (10400)\ttotal: 11m 50s\tremaining: 5m 14s\n",
      "10450:\tlearn: 0.4153512\ttest: 0.5108956\tbest: 0.5108956 (10450)\ttotal: 11m 55s\tremaining: 5m 11s\n",
      "10500:\tlearn: 0.4149125\ttest: 0.5108699\tbest: 0.5108699 (10500)\ttotal: 11m 59s\tremaining: 5m 8s\n",
      "10550:\tlearn: 0.4145102\ttest: 0.5108400\tbest: 0.5108400 (10550)\ttotal: 12m 2s\tremaining: 5m 4s\n",
      "10600:\tlearn: 0.4140667\ttest: 0.5108011\tbest: 0.5108011 (10600)\ttotal: 12m 6s\tremaining: 5m 1s\n",
      "10650:\tlearn: 0.4136412\ttest: 0.5107840\tbest: 0.5107812 (10647)\ttotal: 12m 10s\tremaining: 4m 58s\n",
      "10700:\tlearn: 0.4131910\ttest: 0.5107508\tbest: 0.5107505 (10699)\ttotal: 12m 14s\tremaining: 4m 54s\n",
      "10750:\tlearn: 0.4127532\ttest: 0.5107270\tbest: 0.5107270 (10750)\ttotal: 12m 18s\tremaining: 4m 51s\n",
      "10800:\tlearn: 0.4123270\ttest: 0.5107142\tbest: 0.5107118 (10783)\ttotal: 12m 21s\tremaining: 4m 48s\n",
      "10850:\tlearn: 0.4119027\ttest: 0.5106838\tbest: 0.5106832 (10848)\ttotal: 12m 25s\tremaining: 4m 45s\n",
      "10900:\tlearn: 0.4114652\ttest: 0.5106732\tbest: 0.5106697 (10893)\ttotal: 12m 28s\tremaining: 4m 41s\n",
      "10950:\tlearn: 0.4110273\ttest: 0.5106535\tbest: 0.5106535 (10950)\ttotal: 12m 32s\tremaining: 4m 38s\n",
      "11000:\tlearn: 0.4105944\ttest: 0.5106309\tbest: 0.5106295 (10990)\ttotal: 12m 36s\tremaining: 4m 34s\n",
      "11050:\tlearn: 0.4101883\ttest: 0.5106179\tbest: 0.5106179 (11050)\ttotal: 12m 39s\tremaining: 4m 31s\n",
      "11100:\tlearn: 0.4097689\ttest: 0.5105887\tbest: 0.5105887 (11100)\ttotal: 12m 43s\tremaining: 4m 28s\n",
      "11150:\tlearn: 0.4093531\ttest: 0.5105577\tbest: 0.5105577 (11150)\ttotal: 12m 46s\tremaining: 4m 24s\n",
      "11200:\tlearn: 0.4089198\ttest: 0.5105442\tbest: 0.5105421 (11199)\ttotal: 12m 49s\tremaining: 4m 21s\n",
      "11250:\tlearn: 0.4084781\ttest: 0.5105235\tbest: 0.5105235 (11250)\ttotal: 12m 53s\tremaining: 4m 17s\n",
      "11300:\tlearn: 0.4080661\ttest: 0.5105003\tbest: 0.5105003 (11300)\ttotal: 12m 57s\tremaining: 4m 14s\n",
      "11350:\tlearn: 0.4076213\ttest: 0.5104747\tbest: 0.5104747 (11350)\ttotal: 13m 1s\tremaining: 4m 11s\n",
      "11400:\tlearn: 0.4072196\ttest: 0.5104516\tbest: 0.5104516 (11400)\ttotal: 13m 5s\tremaining: 4m 7s\n",
      "11450:\tlearn: 0.4067796\ttest: 0.5104364\tbest: 0.5104361 (11448)\ttotal: 13m 9s\tremaining: 4m 4s\n",
      "11500:\tlearn: 0.4063676\ttest: 0.5104225\tbest: 0.5104206 (11497)\ttotal: 13m 12s\tremaining: 4m 1s\n",
      "11550:\tlearn: 0.4059684\ttest: 0.5103965\tbest: 0.5103949 (11544)\ttotal: 13m 16s\tremaining: 3m 57s\n",
      "11600:\tlearn: 0.4055311\ttest: 0.5103884\tbest: 0.5103884 (11600)\ttotal: 13m 19s\tremaining: 3m 54s\n",
      "11650:\tlearn: 0.4051320\ttest: 0.5103708\tbest: 0.5103708 (11647)\ttotal: 13m 22s\tremaining: 3m 50s\n",
      "11700:\tlearn: 0.4047195\ttest: 0.5103479\tbest: 0.5103479 (11700)\ttotal: 13m 27s\tremaining: 3m 47s\n",
      "11750:\tlearn: 0.4043116\ttest: 0.5103365\tbest: 0.5103365 (11750)\ttotal: 13m 31s\tremaining: 3m 44s\n",
      "11800:\tlearn: 0.4038857\ttest: 0.5103324\tbest: 0.5103314 (11798)\ttotal: 13m 34s\tremaining: 3m 40s\n",
      "11850:\tlearn: 0.4034369\ttest: 0.5103135\tbest: 0.5103133 (11846)\ttotal: 13m 38s\tremaining: 3m 37s\n",
      "11900:\tlearn: 0.4030428\ttest: 0.5103068\tbest: 0.5103068 (11900)\ttotal: 13m 42s\tremaining: 3m 34s\n",
      "11950:\tlearn: 0.4026377\ttest: 0.5102910\tbest: 0.5102909 (11928)\ttotal: 13m 46s\tremaining: 3m 30s\n",
      "12000:\tlearn: 0.4022480\ttest: 0.5102681\tbest: 0.5102681 (12000)\ttotal: 13m 49s\tremaining: 3m 27s\n",
      "12050:\tlearn: 0.4018478\ttest: 0.5102568\tbest: 0.5102568 (12050)\ttotal: 13m 53s\tremaining: 3m 24s\n",
      "12100:\tlearn: 0.4014381\ttest: 0.5102425\tbest: 0.5102425 (12100)\ttotal: 13m 57s\tremaining: 3m 20s\n",
      "12150:\tlearn: 0.4010308\ttest: 0.5102348\tbest: 0.5102341 (12141)\ttotal: 14m\tremaining: 3m 17s\n",
      "12200:\tlearn: 0.4006492\ttest: 0.5102317\tbest: 0.5102302 (12160)\ttotal: 14m 4s\tremaining: 3m 13s\n",
      "12250:\tlearn: 0.4002623\ttest: 0.5102148\tbest: 0.5102148 (12250)\ttotal: 14m 8s\tremaining: 3m 10s\n",
      "12300:\tlearn: 0.3998565\ttest: 0.5102068\tbest: 0.5102065 (12297)\ttotal: 14m 12s\tremaining: 3m 7s\n",
      "12350:\tlearn: 0.3994459\ttest: 0.5101856\tbest: 0.5101838 (12349)\ttotal: 14m 16s\tremaining: 3m 3s\n",
      "12400:\tlearn: 0.3990598\ttest: 0.5101693\tbest: 0.5101689 (12399)\ttotal: 14m 19s\tremaining: 3m\n",
      "12450:\tlearn: 0.3987079\ttest: 0.5101645\tbest: 0.5101625 (12442)\ttotal: 14m 23s\tremaining: 2m 56s\n",
      "12500:\tlearn: 0.3983222\ttest: 0.5101407\tbest: 0.5101389 (12496)\ttotal: 14m 26s\tremaining: 2m 53s\n",
      "12550:\tlearn: 0.3979188\ttest: 0.5101277\tbest: 0.5101273 (12544)\ttotal: 14m 30s\tremaining: 2m 49s\n",
      "12600:\tlearn: 0.3975419\ttest: 0.5101090\tbest: 0.5101090 (12600)\ttotal: 14m 34s\tremaining: 2m 46s\n",
      "12650:\tlearn: 0.3971422\ttest: 0.5100998\tbest: 0.5100998 (12650)\ttotal: 14m 38s\tremaining: 2m 43s\n",
      "12700:\tlearn: 0.3967315\ttest: 0.5100948\tbest: 0.5100946 (12699)\ttotal: 14m 42s\tremaining: 2m 39s\n",
      "12750:\tlearn: 0.3963202\ttest: 0.5100794\tbest: 0.5100794 (12750)\ttotal: 14m 46s\tremaining: 2m 36s\n",
      "12800:\tlearn: 0.3959329\ttest: 0.5100727\tbest: 0.5100713 (12796)\ttotal: 14m 50s\tremaining: 2m 32s\n",
      "12850:\tlearn: 0.3955317\ttest: 0.5100637\tbest: 0.5100637 (12850)\ttotal: 14m 53s\tremaining: 2m 29s\n",
      "12900:\tlearn: 0.3951552\ttest: 0.5100477\tbest: 0.5100477 (12900)\ttotal: 14m 57s\tremaining: 2m 25s\n",
      "12950:\tlearn: 0.3947627\ttest: 0.5100348\tbest: 0.5100345 (12947)\ttotal: 15m\tremaining: 2m 22s\n",
      "13000:\tlearn: 0.3943927\ttest: 0.5100188\tbest: 0.5100184 (12998)\ttotal: 15m 4s\tremaining: 2m 19s\n",
      "13050:\tlearn: 0.3940127\ttest: 0.5100089\tbest: 0.5100064 (13047)\ttotal: 15m 8s\tremaining: 2m 15s\n",
      "13100:\tlearn: 0.3936561\ttest: 0.5099943\tbest: 0.5099943 (13100)\ttotal: 15m 12s\tremaining: 2m 12s\n",
      "13150:\tlearn: 0.3932721\ttest: 0.5099819\tbest: 0.5099819 (13150)\ttotal: 15m 15s\tremaining: 2m 8s\n",
      "13200:\tlearn: 0.3928580\ttest: 0.5099794\tbest: 0.5099781 (13177)\ttotal: 15m 19s\tremaining: 2m 5s\n",
      "13250:\tlearn: 0.3924674\ttest: 0.5099709\tbest: 0.5099709 (13250)\ttotal: 15m 22s\tremaining: 2m 1s\n",
      "13300:\tlearn: 0.3920792\ttest: 0.5099578\tbest: 0.5099578 (13299)\ttotal: 15m 26s\tremaining: 1m 58s\n",
      "13350:\tlearn: 0.3917004\ttest: 0.5099496\tbest: 0.5099470 (13348)\ttotal: 15m 29s\tremaining: 1m 54s\n",
      "13400:\tlearn: 0.3913388\ttest: 0.5099428\tbest: 0.5099428 (13400)\ttotal: 15m 32s\tremaining: 1m 51s\n",
      "13450:\tlearn: 0.3909489\ttest: 0.5099228\tbest: 0.5099228 (13450)\ttotal: 15m 36s\tremaining: 1m 47s\n",
      "13500:\tlearn: 0.3905734\ttest: 0.5099119\tbest: 0.5099116 (13498)\ttotal: 15m 39s\tremaining: 1m 44s\n",
      "13550:\tlearn: 0.3901809\ttest: 0.5099072\tbest: 0.5099021 (13534)\ttotal: 15m 43s\tremaining: 1m 40s\n",
      "13600:\tlearn: 0.3898104\ttest: 0.5098911\tbest: 0.5098911 (13600)\ttotal: 15m 46s\tremaining: 1m 37s\n",
      "13650:\tlearn: 0.3894412\ttest: 0.5098833\tbest: 0.5098820 (13644)\ttotal: 15m 50s\tremaining: 1m 33s\n",
      "13700:\tlearn: 0.3890770\ttest: 0.5098672\tbest: 0.5098657 (13695)\ttotal: 15m 53s\tremaining: 1m 30s\n",
      "13750:\tlearn: 0.3886654\ttest: 0.5098718\tbest: 0.5098646 (13733)\ttotal: 15m 58s\tremaining: 1m 27s\n",
      "13800:\tlearn: 0.3882998\ttest: 0.5098609\tbest: 0.5098597 (13799)\ttotal: 16m 1s\tremaining: 1m 23s\n",
      "13850:\tlearn: 0.3879206\ttest: 0.5098448\tbest: 0.5098446 (13849)\ttotal: 16m 4s\tremaining: 1m 20s\n",
      "13900:\tlearn: 0.3875628\ttest: 0.5098343\tbest: 0.5098330 (13894)\ttotal: 16m 7s\tremaining: 1m 16s\n",
      "13950:\tlearn: 0.3871930\ttest: 0.5098167\tbest: 0.5098167 (13950)\ttotal: 16m 11s\tremaining: 1m 13s\n",
      "14000:\tlearn: 0.3868310\ttest: 0.5098020\tbest: 0.5098020 (14000)\ttotal: 16m 14s\tremaining: 1m 9s\n",
      "14050:\tlearn: 0.3864543\ttest: 0.5097931\tbest: 0.5097901 (14041)\ttotal: 16m 17s\tremaining: 1m 6s\n",
      "14100:\tlearn: 0.3860834\ttest: 0.5097928\tbest: 0.5097901 (14041)\ttotal: 16m 21s\tremaining: 1m 2s\n",
      "14150:\tlearn: 0.3857017\ttest: 0.5097791\tbest: 0.5097764 (14137)\ttotal: 16m 24s\tremaining: 59.1s\n",
      "14200:\tlearn: 0.3853435\ttest: 0.5097730\tbest: 0.5097716 (14190)\ttotal: 16m 27s\tremaining: 55.6s\n",
      "14250:\tlearn: 0.3849884\ttest: 0.5097642\tbest: 0.5097642 (14250)\ttotal: 16m 31s\tremaining: 52.1s\n",
      "14300:\tlearn: 0.3846303\ttest: 0.5097527\tbest: 0.5097525 (14295)\ttotal: 16m 34s\tremaining: 48.6s\n",
      "14350:\tlearn: 0.3842644\ttest: 0.5097479\tbest: 0.5097447 (14342)\ttotal: 16m 38s\tremaining: 45.2s\n",
      "14400:\tlearn: 0.3839143\ttest: 0.5097367\tbest: 0.5097349 (14396)\ttotal: 16m 42s\tremaining: 41.7s\n",
      "14450:\tlearn: 0.3835686\ttest: 0.5097383\tbest: 0.5097349 (14396)\ttotal: 16m 45s\tremaining: 38.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5097349019\n",
      "bestIteration = 14396\n",
      "\n",
      "Shrink model to first 14397 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostRegressor at 0x246be059390>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1.fit(X_train, y_train, verbose=50, eval_set=(X_test, y_test), early_stopping_rounds=100,\n",
    "         use_best_model=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(max_depth=9,\n",
    "                   booster='gbtree',\n",
    "                   eta=0.01,\n",
    "                   colsample_bytree=0.66,\n",
    "                   subsample=0.76,\n",
    "                   min_child_weight=22, gamma=1,\n",
    "\n",
    "                   seed=75,\n",
    "                   objective='reg:squarederror',\n",
    "                   eval_metric='rmse',\n",
    "                   l1=16,\n",
    "                   n_estimators = 15000\n",
    "                   )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:57:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"l1\" } are not used.\n",
      "\n",
      "[0]\tvalidation_0-rmse:1.93330\n",
      "[30]\tvalidation_0-rmse:1.48929\n",
      "[60]\tvalidation_0-rmse:1.16819\n",
      "[90]\tvalidation_0-rmse:0.94252\n",
      "[120]\tvalidation_0-rmse:0.78856\n",
      "[150]\tvalidation_0-rmse:0.68611\n",
      "[180]\tvalidation_0-rmse:0.62076\n",
      "[210]\tvalidation_0-rmse:0.57937\n",
      "[240]\tvalidation_0-rmse:0.55407\n",
      "[270]\tvalidation_0-rmse:0.53858\n",
      "[300]\tvalidation_0-rmse:0.52946\n",
      "[330]\tvalidation_0-rmse:0.52354\n",
      "[360]\tvalidation_0-rmse:0.51958\n",
      "[390]\tvalidation_0-rmse:0.51691\n",
      "[420]\tvalidation_0-rmse:0.51494\n",
      "[450]\tvalidation_0-rmse:0.51374\n",
      "[480]\tvalidation_0-rmse:0.51287\n",
      "[510]\tvalidation_0-rmse:0.51216\n",
      "[540]\tvalidation_0-rmse:0.51166\n",
      "[570]\tvalidation_0-rmse:0.51109\n",
      "[600]\tvalidation_0-rmse:0.51084\n",
      "[630]\tvalidation_0-rmse:0.51049\n",
      "[660]\tvalidation_0-rmse:0.51024\n",
      "[690]\tvalidation_0-rmse:0.51004\n",
      "[720]\tvalidation_0-rmse:0.50981\n",
      "[750]\tvalidation_0-rmse:0.50967\n",
      "[780]\tvalidation_0-rmse:0.50946\n",
      "[810]\tvalidation_0-rmse:0.50919\n",
      "[840]\tvalidation_0-rmse:0.50900\n",
      "[870]\tvalidation_0-rmse:0.50882\n",
      "[900]\tvalidation_0-rmse:0.50871\n",
      "[930]\tvalidation_0-rmse:0.50862\n",
      "[960]\tvalidation_0-rmse:0.50852\n",
      "[990]\tvalidation_0-rmse:0.50843\n",
      "[1020]\tvalidation_0-rmse:0.50830\n",
      "[1050]\tvalidation_0-rmse:0.50822\n",
      "[1080]\tvalidation_0-rmse:0.50813\n",
      "[1110]\tvalidation_0-rmse:0.50803\n",
      "[1140]\tvalidation_0-rmse:0.50788\n",
      "[1170]\tvalidation_0-rmse:0.50785\n",
      "[1200]\tvalidation_0-rmse:0.50780\n",
      "[1230]\tvalidation_0-rmse:0.50772\n",
      "[1260]\tvalidation_0-rmse:0.50772\n",
      "[1290]\tvalidation_0-rmse:0.50761\n",
      "[1320]\tvalidation_0-rmse:0.50752\n",
      "[1350]\tvalidation_0-rmse:0.50747\n",
      "[1380]\tvalidation_0-rmse:0.50737\n",
      "[1410]\tvalidation_0-rmse:0.50731\n",
      "[1440]\tvalidation_0-rmse:0.50721\n",
      "[1470]\tvalidation_0-rmse:0.50717\n",
      "[1500]\tvalidation_0-rmse:0.50711\n",
      "[1530]\tvalidation_0-rmse:0.50708\n",
      "[1560]\tvalidation_0-rmse:0.50705\n",
      "[1590]\tvalidation_0-rmse:0.50702\n",
      "[1620]\tvalidation_0-rmse:0.50698\n",
      "[1650]\tvalidation_0-rmse:0.50691\n",
      "[1680]\tvalidation_0-rmse:0.50685\n",
      "[1710]\tvalidation_0-rmse:0.50682\n",
      "[1740]\tvalidation_0-rmse:0.50677\n",
      "[1770]\tvalidation_0-rmse:0.50676\n",
      "[1800]\tvalidation_0-rmse:0.50676\n",
      "[1830]\tvalidation_0-rmse:0.50681\n",
      "[1844]\tvalidation_0-rmse:0.50679\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.66,\n             early_stopping_rounds=None, enable_categorical=False, eta=0.01,\n             eval_metric='rmse', feature_types=None, gamma=1, gpu_id=-1,\n             grow_policy='depthwise', importance_type=None,\n             interaction_constraints='', l1=16, learning_rate=0.00999999978,\n             max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=22,\n             missing=nan, monotone_constraints='()', n_estimators=15000,\n             n_jobs=0, num_parallel_tree=1, ...)",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.66,\n             early_stopping_rounds=None, enable_categorical=False, eta=0.01,\n             eval_metric=&#x27;rmse&#x27;, feature_types=None, gamma=1, gpu_id=-1,\n             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, l1=16, learning_rate=0.00999999978,\n             max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=22,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=15000,\n             n_jobs=0, num_parallel_tree=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.66,\n             early_stopping_rounds=None, enable_categorical=False, eta=0.01,\n             eval_metric=&#x27;rmse&#x27;, feature_types=None, gamma=1, gpu_id=-1,\n             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, l1=16, learning_rate=0.00999999978,\n             max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=22,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=15000,\n             n_jobs=0, num_parallel_tree=1, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "xgb1 = XGBRegressor(objective='reg:linear',\n",
    "                   eval_metric='rmse',\n",
    "                   eta=0.001,\n",
    "                   max_depth=10,\n",
    "                   subsample=0.6,\n",
    "                   colsample_bytree=0.6,\n",
    "                   alpha=0.001,\n",
    "                   random_state=17,\n",
    "                   silent=True,\n",
    "                   n_estimators=15000,\n",
    "                   n_jobs=-1,\n",
    "                   seed=75)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:59:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[0]\tvalidation_0-rmse:1.94918\n",
      "[150]\tvalidation_0-rmse:1.70824\n",
      "[300]\tvalidation_0-rmse:1.50294\n",
      "[450]\tvalidation_0-rmse:1.32887\n",
      "[600]\tvalidation_0-rmse:1.18092\n",
      "[750]\tvalidation_0-rmse:1.05665\n",
      "[900]\tvalidation_0-rmse:0.95255\n",
      "[1050]\tvalidation_0-rmse:0.86650\n",
      "[1200]\tvalidation_0-rmse:0.79523\n",
      "[1350]\tvalidation_0-rmse:0.73722\n",
      "[1500]\tvalidation_0-rmse:0.69002\n",
      "[1650]\tvalidation_0-rmse:0.65196\n",
      "[1800]\tvalidation_0-rmse:0.62157\n",
      "[1950]\tvalidation_0-rmse:0.59749\n",
      "[2100]\tvalidation_0-rmse:0.57858\n",
      "[2250]\tvalidation_0-rmse:0.56366\n",
      "[2400]\tvalidation_0-rmse:0.55192\n",
      "[2550]\tvalidation_0-rmse:0.54276\n",
      "[2700]\tvalidation_0-rmse:0.53563\n",
      "[2850]\tvalidation_0-rmse:0.53002\n",
      "[3000]\tvalidation_0-rmse:0.52565\n",
      "[3150]\tvalidation_0-rmse:0.52214\n",
      "[3300]\tvalidation_0-rmse:0.51943\n",
      "[3450]\tvalidation_0-rmse:0.51722\n",
      "[3600]\tvalidation_0-rmse:0.51546\n",
      "[3750]\tvalidation_0-rmse:0.51401\n",
      "[3900]\tvalidation_0-rmse:0.51282\n",
      "[4050]\tvalidation_0-rmse:0.51186\n",
      "[4200]\tvalidation_0-rmse:0.51105\n",
      "[4350]\tvalidation_0-rmse:0.51041\n",
      "[4500]\tvalidation_0-rmse:0.50985\n",
      "[4650]\tvalidation_0-rmse:0.50936\n",
      "[4800]\tvalidation_0-rmse:0.50898\n",
      "[4950]\tvalidation_0-rmse:0.50864\n",
      "[5100]\tvalidation_0-rmse:0.50833\n",
      "[5250]\tvalidation_0-rmse:0.50804\n",
      "[5400]\tvalidation_0-rmse:0.50778\n",
      "[5550]\tvalidation_0-rmse:0.50756\n",
      "[5700]\tvalidation_0-rmse:0.50736\n",
      "[5850]\tvalidation_0-rmse:0.50716\n",
      "[6000]\tvalidation_0-rmse:0.50701\n",
      "[6150]\tvalidation_0-rmse:0.50685\n",
      "[6300]\tvalidation_0-rmse:0.50670\n",
      "[6450]\tvalidation_0-rmse:0.50657\n",
      "[6600]\tvalidation_0-rmse:0.50645\n",
      "[6750]\tvalidation_0-rmse:0.50631\n",
      "[6900]\tvalidation_0-rmse:0.50619\n",
      "[7050]\tvalidation_0-rmse:0.50610\n",
      "[7200]\tvalidation_0-rmse:0.50601\n",
      "[7350]\tvalidation_0-rmse:0.50591\n",
      "[7500]\tvalidation_0-rmse:0.50581\n",
      "[7650]\tvalidation_0-rmse:0.50572\n",
      "[7800]\tvalidation_0-rmse:0.50563\n",
      "[7950]\tvalidation_0-rmse:0.50556\n",
      "[8100]\tvalidation_0-rmse:0.50548\n",
      "[8250]\tvalidation_0-rmse:0.50542\n",
      "[8400]\tvalidation_0-rmse:0.50536\n",
      "[8550]\tvalidation_0-rmse:0.50527\n",
      "[8700]\tvalidation_0-rmse:0.50521\n",
      "[8850]\tvalidation_0-rmse:0.50515\n",
      "[9000]\tvalidation_0-rmse:0.50509\n",
      "[9150]\tvalidation_0-rmse:0.50503\n",
      "[9300]\tvalidation_0-rmse:0.50498\n",
      "[9450]\tvalidation_0-rmse:0.50492\n",
      "[9600]\tvalidation_0-rmse:0.50486\n",
      "[9750]\tvalidation_0-rmse:0.50481\n",
      "[9900]\tvalidation_0-rmse:0.50476\n",
      "[10050]\tvalidation_0-rmse:0.50471\n",
      "[10200]\tvalidation_0-rmse:0.50468\n",
      "[10350]\tvalidation_0-rmse:0.50465\n",
      "[10500]\tvalidation_0-rmse:0.50463\n",
      "[10650]\tvalidation_0-rmse:0.50459\n",
      "[10800]\tvalidation_0-rmse:0.50455\n",
      "[10950]\tvalidation_0-rmse:0.50452\n",
      "[11100]\tvalidation_0-rmse:0.50450\n",
      "[11250]\tvalidation_0-rmse:0.50448\n",
      "[11400]\tvalidation_0-rmse:0.50445\n",
      "[11550]\tvalidation_0-rmse:0.50442\n",
      "[11700]\tvalidation_0-rmse:0.50441\n",
      "[11850]\tvalidation_0-rmse:0.50438\n",
      "[12000]\tvalidation_0-rmse:0.50438\n",
      "[12150]\tvalidation_0-rmse:0.50436\n",
      "[12300]\tvalidation_0-rmse:0.50434\n",
      "[12450]\tvalidation_0-rmse:0.50433\n",
      "[12600]\tvalidation_0-rmse:0.50430\n",
      "[12750]\tvalidation_0-rmse:0.50428\n",
      "[12900]\tvalidation_0-rmse:0.50427\n",
      "[13050]\tvalidation_0-rmse:0.50424\n",
      "[13200]\tvalidation_0-rmse:0.50422\n",
      "[13350]\tvalidation_0-rmse:0.50421\n",
      "[13408]\tvalidation_0-rmse:0.50420\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBRegressor(alpha=0.001, base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n             early_stopping_rounds=None, enable_categorical=False, eta=0.001,\n             eval_metric='rmse', feature_types=None, gamma=0, gpu_id=-1,\n             grow_policy='depthwise', importance_type=None,\n             interaction_constraints='', learning_rate=0.00100000005,\n             max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=15000,\n             n_jobs=-1, num_parallel_tree=1, ...)",
      "text/html": "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0.001, base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n             early_stopping_rounds=None, enable_categorical=False, eta=0.001,\n             eval_metric=&#x27;rmse&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, learning_rate=0.00100000005,\n             max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=15000,\n             n_jobs=-1, num_parallel_tree=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0.001, base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n             early_stopping_rounds=None, enable_categorical=False, eta=0.001,\n             eval_metric=&#x27;rmse&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, learning_rate=0.00100000005,\n             max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=15000,\n             n_jobs=-1, num_parallel_tree=1, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=150)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.17058158,  0.64814781, -0.16468447, ...,  0.54025721,\n         1.61407688,  2.22713352],\n       [-1.34357023, -0.40240812, -0.60461587, ..., -0.73737375,\n        -0.73103603, -0.36730672],\n       [ 2.10069904, -0.48322012,  1.05636256, ...,  0.22084947,\n        -0.93384109, -0.1458883 ],\n       ...,\n       [-0.63208641, -1.04890408, -0.37490787, ...,  0.54025721,\n         0.79383901,  0.73656544],\n       [ 1.83512339, -1.53377605,  1.27028853, ...,  0.22084947,\n        -0.8775127 , -0.30238446],\n       [ 1.01614725,  0.24408783,  0.41879847, ...,  0.54025721,\n         1.30419579, -0.93964227]])"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_test_scale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "pred_test_XGB = xgb1.predict(fin_test_scale)\n",
    "pred_test_LGBM = lgb1.predict(fin_test_scale)\n",
    "pred_test_cat = cat1.predict(fin_test_scale)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  MedHouseVal\n0      37137     2.079751\n1      37138     2.079751\n2      37139     2.079751\n3      37140     2.079751\n4      37141     2.079751\n...      ...          ...\n24754  61891     2.079751\n24755  61892     2.079751\n24756  61893     2.079751\n24757  61894     2.079751\n24758  61895     2.079751\n\n[24759 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>MedHouseVal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37137</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37138</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37139</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37140</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37141</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24754</th>\n      <td>61891</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>24755</th>\n      <td>61892</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>24756</th>\n      <td>61893</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>24757</th>\n      <td>61894</td>\n      <td>2.079751</td>\n    </tr>\n    <tr>\n      <th>24758</th>\n      <td>61895</td>\n      <td>2.079751</td>\n    </tr>\n  </tbody>\n</table>\n<p>24759 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": sub.iloc[:,0].tolist(), \"MedHouseVal\":pred_test_XGB}).to_csv(\"submission5.csv\", index=False)\n",
    "pd.DataFrame({\"id\": sub.iloc[:,0].tolist(), \"MedHouseVal\":pred_test_LGBM}).to_csv(\"submission6.csv\", index=False)\n",
    "pd.DataFrame({\"id\": sub.iloc[:,0].tolist(), \"MedHouseVal\":pred_test_cat}).to_csv(\"submission7.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb[\"MedHouseVal\"] = pred_test_LGBM\n",
    "\n",
    "sub_xgb = pd.DataFrame()\n",
    "sub_xgb[\"MedHouseVal\"] = pred_test_XGB\n",
    "\n",
    "sub_cat = pd.DataFrame()\n",
    "sub_cat[\"MedHouseVal\"] = pred_test_cat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "sub[\"MedHouseVal\"] = (sub_xgb[\"MedHouseVal\"] * 0.4 + sub_lgb[\"MedHouseVal\"] * 0.4 + sub_cat[\"MedHouseVal\"] * 0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "sub.to_csv('sub_final1_scaled_blend.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
